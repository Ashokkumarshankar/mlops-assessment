{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-08-28T11:08:17.925917Z","iopub.status.busy":"2023-08-28T11:08:17.925510Z","iopub.status.idle":"2023-08-28T11:08:17.932813Z","shell.execute_reply":"2023-08-28T11:08:17.931791Z","shell.execute_reply.started":"2023-08-28T11:08:17.925885Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-08-28T11:08:19.250666Z","iopub.status.busy":"2023-08-28T11:08:19.249951Z","iopub.status.idle":"2023-08-28T11:08:20.174418Z","shell.execute_reply":"2023-08-28T11:08:20.173337Z","shell.execute_reply.started":"2023-08-28T11:08:19.250623Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44d0fa993ce34c68b144de465f5e75ad","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","emotions = load_dataset('SetFit/Emotion')"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-08-28T11:08:20.177401Z","iopub.status.busy":"2023-08-28T11:08:20.176684Z","iopub.status.idle":"2023-08-28T11:08:20.184533Z","shell.execute_reply":"2023-08-28T11:08:20.183553Z","shell.execute_reply.started":"2023-08-28T11:08:20.177362Z"},"trusted":true},"outputs":[{"data":{"text/plain":["datasets.dataset_dict.DatasetDict"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["type(emotions)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-08-28T11:08:20.186957Z","iopub.status.busy":"2023-08-28T11:08:20.185899Z","iopub.status.idle":"2023-08-28T11:08:20.199027Z","shell.execute_reply":"2023-08-28T11:08:20.197936Z","shell.execute_reply.started":"2023-08-28T11:08:20.186922Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['text', 'label', 'label_text'],\n","    num_rows: 16000\n","})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["emotions['train']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# from nlp import list_datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# !pip install nlp"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","# !pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install mlflow "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_ds = emotions['train']\n","train_ds"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["emotions.set_format('pandas')\n","df = emotions['train'][:]\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# def label_int2str(row):\n","#     return emotions['train'].features['label'].int2str(row)\n","\n","# df['label_name'] = df['label'].apply(label_int2str)\n","# df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def tokenize(batch):\n","    return tokenizer(batch[\"text\"], padding=True, truncation=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["emotions.reset_format()\n","emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["emotions_encoded['train'].column_names\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","from transformers import AutoModel\n","\n","model_ckpt = \"distilbert-base-uncased\"\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = AutoModel.from_pretrained(model_ckpt).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["text = \"this is a test\"\n","sample_inputs = tokenizer(text, return_tensors=\"pt\")\n","print(f\"Input tensor shape: {sample_inputs['input_ids'].size()}\\n\"\n","      f\"Tokenized text: {tokenizer.convert_ids_to_tokens(sample_inputs['input_ids'][0])}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["inputs = {k:v.to(device) for k,v in sample_inputs.items()}\n","\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","    print(outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def extract_hidden_states(batch):\n","    inputs = {k:v.to(device) for k, v in batch.items()\n","    if k in tokenizer.model_input_names}\n","    with torch.no_grad():\n","        last_hidden_state = model(**inputs).last_hidden_state\n","\n","    return {\"hidden state\": last_hidden_state[:, 0].cpu().numpy()}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","emotions_encoded.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["emotions_encoded.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'label'])\n","emotions_hidden = emotions_encoded.map(\n","    extract_hidden_states, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","X_train = np.array(emotions_hidden[\"train\"][\"hidden state\"])\n","X_valid = np.array(emotions_hidden[\"validation\"][\"hidden state\"])\n","y_train = np.array(emotions_hidden[\"train\"][\"label\"])\n","y_valid = np.array(emotions_hidden[\"validation\"][\"label\"])\n","print(X_train.shape, X_valid.shape)\n","\n","\n","\n","\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import MinMaxScaler\n","\n","pca = PCA(n_components=2)\n","\n","x_scaled = MinMaxScaler().fit_transform(X_train)\n","x_2d = pca.fit_transform(x_scaled)\n","x_2d.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification\n","\n","num_labels = 6\n","model = (AutoModelForSequenceClassification\n","        .from_pretrained(model_ckpt, num_labels=num_labels)\n","        .to(device))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, f1_score\n","\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    f1 = f1_score(labels, preds, average=\"weighted\")\n","    acc = accuracy_score(labels, preds)\n","    return {\"accuracy\": acc, \"f1\": f1}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import Trainer, TrainingArguments\n","\n","batch_size = 64\n","logging_steps = len(emotions_encoded[\"train\"]) // batch_size\n","model_name = f\"{model_ckpt}-finetuned-emotion\"\n","\n","training_args = TrainingArguments(\n","    output_dir=model_name,\n","    num_train_epochs=2,\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    weight_decay=0.01,\n","    evaluation_strategy=\"epoch\",\n","    disable_tqdm=False,\n","    logging_steps=logging_steps,\n","    log_level=\"error\",\n","    report_to=\"none\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# trainer = Trainer(\n","#     model=model,\n","#     args=training_args,\n","#     compute_metrics=compute_metrics,\n","#     train_dataset=emotions_encoded['train'],\n","#     eval_dataset=emotions_encoded['validation'],\n","#     tokenizer=tokenizer,\n","# )\n","\n","# trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# !pip install mlflow \n","import mlflow\n","from transformers import pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","# mlflow.set_experiment(\"Distill Bert\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["experiment_name = \"Distill Bert\"\n","experiment = mlflow.get_experiment_by_name(experiment_name)\n","if experiment is None:\n","    experiment_id = mlflow.create_experiment(experiment_name)\n","else:\n","    experiment_id = experiment.experiment_id"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import mlflow\n","# from transformers import TrainerCallback\n","\n","# class MLflowCallback(TrainerCallback):\n","#     def __init__(self, mlflow_experiment_name, mlflow_run_name):\n","#         self.mlflow_experiment_name = mlflow_experiment_name\n","#         self.mlflow_run_name = mlflow_run_name\n","\n","#     def on_train_begin(self, args, state, control, model=None, **kwargs):\n","#         mlflow.set_experiment(self.mlflow_experiment_name)\n","#         mlflow.start_run(run_name=self.mlflow_run_name)\n","        \n","#         artifact_uri = \"/path/to/artifacts\"  # Replace with your actual logic\n","#         self.artifact_uri = artifact_uri.replace(\"{artifactUri}\", mlflow.active_run().info.artifact_uri)\n","#     def on_train_end(self, args, state, control, model=None, **kwargs):\n","#         mlflow.end_run()\n","\n","#     def on_epoch_end(self, args, state, control, **kwargs):\n","#         metrics = state.metric\n","#         for metric_name, metric_value in metrics.items():\n","#             mlflow.log_metric(metric_name, metric_value)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mlflow.end_run()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mlflow.set_tracking_uri(\"http://http://13.233.157.244:5001/\")\n","# s3://your-bucket-name/mlflow-artifacts\n","\n","experiment_name = \"Distill Bert\"\n","experiment = mlflow.get_experiment_by_name(experiment_name)\n","if experiment is None:\n","    experiment_id = mlflow.create_experiment(experiment_name)\n","else:\n","    experiment_id = experiment.experiment_id\n","\n","batch_size = 64\n","logging_steps = len(emotions_encoded[\"train\"]) // batch_size\n","model_name = f\"{model_ckpt}-finetuned-emotion\"\n","\n","training_args = TrainingArguments(\n","    output_dir=model_name,\n","    num_train_epochs=2,\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    weight_decay=0.01,\n","    evaluation_strategy=\"epoch\",\n","    disable_tqdm=False,\n","    logging_steps=logging_steps,\n","    log_level=\"error\",\n","    report_to=\"none\"\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset=emotions_encoded['train'],\n","    eval_dataset=emotions_encoded['validation'],\n","    tokenizer=tokenizer,\n",")\n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-08-28T11:08:13.642333Z","iopub.status.busy":"2023-08-28T11:08:13.641935Z","iopub.status.idle":"2023-08-28T11:08:13.648514Z","shell.execute_reply":"2023-08-28T11:08:13.647235Z","shell.execute_reply.started":"2023-08-28T11:08:13.642299Z"},"trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from mlflow.models import infer_signature"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# trainer.train()\n","model_checkpoint_path = os.path.join(\"/kaggle/working\", \"pytorch_model.bin\")\n","trainer.save_model(model_checkpoint_path)\n","print('sm')\n","mlflow.pytorch.autolog()\n","print('al')\n","with mlflow.start_run(experiment_id=experiment_id, run_name=\"Run 11\") as run:\n","    mlflow.log_params({\n","        \"num_train_epochs\": 2,\n","        \"learning_rate\": 2e-5,\n","        # ... Other training parameters ...\n","    })\n","    for metric_name, metric_value in trainer.evaluate().items():\n","        mlflow.log_metric(metric_name, metric_value)\n","#     mlflow.pytorch.autolog()\n","    print('met')\n","    mlflow.pytorch.log_model(model, \"distilbert_emotions_model\",artifact_path=\"artifacts\",code_paths=[models_dir])\n","    print('lm')\n","    mlflow.end_run()\n","print('ok')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import mlflow\n","import pytorch_lightning as pl\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForSequenceClassification\n","from transformers import pipeline\n","from datasets import load_dataset\n","from sklearn.metrics import accuracy_score, f1_score\n","from transformers import Trainer, TrainingArguments\n","import torch\n","import torch.nn as nn\n","\n","from transformers import AutoModel\n","\n","\n","class EmotionModel(pl.LightningModule):\n","    def __init__(self, model_ckpt):\n","        super().__init__()\n","        self.model = AutoModelForSequenceClassification.from_pretrained(model_ckpt)\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n","        self.batch_size = 64\n","        self.logging_steps = len(emotions_encoded[\"train\"]) // self.batch_size\n","\n","    def forward(self, batch):\n","        # Implement the forward pass of the model here\n","        return self.model(batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n","    \n","    def compute_metrics(self, pred):\n","        labels = pred.label_ids\n","        preds = pred.predictions.argmax(-1)\n","        f1 = f1_score(labels, preds, average=\"weighted\")\n","        acc = accuracy_score(labels, preds)\n","        return {\"accuracy\": acc, \"f1\": f1}\n","\n","    def training_step(self, batch, batch_idx):\n","        outputs = self(batch)\n","        loss = outputs.loss\n","        self.log('train_loss', loss, on_step=True, on_epoch=True)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        outputs = self(batch)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","        preds = torch.argmax(logits, dim=1)\n","        labels = batch[\"label\"]\n","\n","        # Calculate accuracy and F1 score only when predictions are available\n","        if preds is not None and labels is not None:\n","            acc = accuracy_score(labels.cpu(), preds.cpu())\n","            f1 = f1_score(labels.cpu(), preds.cpu(), average='weighted')\n","\n","            self.log('val_loss', loss, on_step=True, on_epoch=True)\n","            self.log('val_acc', acc, on_step=False, on_epoch=True)\n","            self.log('val_f1', f1, on_step=False, on_epoch=True)\n","\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-5)\n","        return optimizer\n","\n","    def train_dataloader(self):\n","        dataset = self._get_dataset(\"train\")  \n","        dataloader = torch.utils.data.DataLoader(\n","            dataset,\n","            batch_size=self.batch_size,\n","            shuffle=True,\n","            num_workers=4\n","        )\n","        return dataloader\n","    \n","    def val_dataloader(self):\n","        dataset = self._get_dataset(\"validation\")  \n","        dataloader = torch.utils.data.DataLoader(\n","            dataset,\n","            batch_size=self.batch_size,\n","            num_workers=4\n","        )\n","        return dataloader\n","    \n","    def _get_dataset(self, split):\n","        emotions = load_dataset('SetFit/Emotion')\n","        dataset = emotions[split]\n","\n","        def tokenize_and_prepare(batch):\n","            tokenized_batch = tokenizer(batch['text'], padding=True, truncation=True)\n","            return {\n","                'input_ids': tokenized_batch['input_ids'],\n","                'attention_mask': tokenized_batch['attention_mask'],\n","                'label': batch['label']\n","            }\n","\n","        tokenized_dataset = dataset.map(tokenize_and_prepare, batched=True, batch_size=None)\n","        tokenized_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'label'])\n","\n","        return tokenized_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mlflow.set_tracking_uri(\"http://13.233.157.244:5001/\")\n","mlflow.pytorch.autolog()\n","experiment_name = \"Distill Bert\"\n","model_ckpt = \"distilbert-base-uncased\"\n","\n","emotions = load_dataset('SetFit/Emotion')\n","emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)\n","emotions_encoded.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'label'])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = EmotionModel(model_ckpt)\n","\n","trainer = pl.Trainer(\n","    max_epochs=2,\n","    devices=2,\n","    accelerator='gpu'\n",")\n","\n","with mlflow.start_run(run_name=\"Run 8\") as run:\n","    trainer.fit(model)\n","    pipe = pipeline(\"text-classification\", model=model_name, batch_size=1, tokenizer=model.tokenizer)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-08-28T10:55:07.320887Z","iopub.status.busy":"2023-08-28T10:55:07.320449Z","iopub.status.idle":"2023-08-28T10:55:12.710230Z","shell.execute_reply":"2023-08-28T10:55:12.709272Z","shell.execute_reply.started":"2023-08-28T10:55:07.320850Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0cbbe9f67fec4663a916469ec1f69a81","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55da1c62b59941a2a6ab34b65e0dffd4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/43410 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28b5bc3251f64cda8696d3e77e377377","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5426 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49a043ae6c574e29a7f9884dbccaec89","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5427 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at squeezebert/squeezebert-uncased were not used when initializing SqueezeBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing SqueezeBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing SqueezeBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from tqdm.notebook import tqdm\n","\n","from datasets import load_dataset\n","import random\n","from sklearn import metrics, model_selection, preprocessing\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","import transformers\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from mlflow.data.pandas_dataset import PandasDataset\n","\n","def seed_everything(seed=73):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    # some cudnn methods can be random even after fixing the seed unless you tell it to be deterministic\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_everything(1234)\n","\n","go_emotions = load_dataset(\"go_emotions\")\n","data = go_emotions.data\n","\n","train, valid, test = data[\"train\"].to_pandas(), data[\"validation\"].to_pandas(), data[\"test\"].to_pandas()\n","\n","mapping = {\n","    0:\"admiration\",\n","    1:\"amusement\",\n","    2:\"anger\",\n","    3:\"annoyance\",\n","    4:\"approval\",\n","    5:\"caring\",\n","    6:\"confusion\",\n","    7:\"curiosity\",\n","    8:\"desire\",\n","    9:\"disappointment\",\n","    10:\"disapproval\",\n","    11:\"disgust\",\n","    12:\"embarrassment\",\n","    13:\"excitement\",\n","    14:\"fear\",\n","    15:\"gratitude\",\n","    16:\"grief\",\n","    17:\"joy\",\n","    18:\"love\",\n","    19:\"nervousness\",\n","    20:\"optimism\",\n","    21:\"pride\",\n","    22:\"realization\",\n","    23:\"relief\",\n","    24:\"remorse\",\n","    25:\"sadness\",\n","    26:\"surprise\",\n","    27:\"neutral\",\n","}\n","\n","n_labels = len(mapping)\n","\n","def one_hot_encoder(df):\n","    one_hot_encoding = []\n","    for i in tqdm(range(len(df))):\n","        temp = [0]*n_labels\n","        label_indices = df.iloc[i][\"labels\"]\n","        for index in label_indices:\n","            temp[index] = 1\n","        one_hot_encoding.append(temp)\n","    return pd.DataFrame(one_hot_encoding)\n","\n","train_ohe_labels = one_hot_encoder(train)\n","valid_ohe_labels = one_hot_encoder(valid)\n","test_ohe_labels = one_hot_encoder(test)\n","\n","\n","train = pd.concat([train, train_ohe_labels], axis=1)\n","valid = pd.concat([valid, valid_ohe_labels], axis=1)\n","test = pd.concat([test, test_ohe_labels], axis=1)\n","\n","def inspect_category_wise_data(label, n=5):\n","    samples = train[train[label] == 1].sample(n)\n","    sentiment = mapping[label]\n","    \n","    print(f\"{n} samples from {sentiment} sentiment: \\n\")\n","    for text in samples[\"text\"]:\n","        print(text, end='\\n\\n')\n","\n","class GoEmotionDataset:\n","    def __init__(self, texts, labels, tokenizer, max_len):\n","        self.texts = texts\n","        self.labels = labels\n","\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","    \n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, index):\n","        text = self.texts[index]\n","        label = self.labels[index]\n","\n","        inputs = self.tokenizer.__call__(text,\n","                                        None,\n","                                        add_special_tokens=True,\n","                                        max_length=self.max_len,\n","                                        padding=\"max_length\",\n","                                        truncation=True,\n","                                        )\n","        ids = inputs[\"input_ids\"]\n","        mask = inputs[\"attention_mask\"]\n","\n","        return {\n","            \"ids\": torch.tensor(ids, dtype=torch.long),\n","            \"mask\": torch.tensor(mask, dtype=torch.long),\n","            \"labels\": torch.tensor(label, dtype=torch.long)\n","        }\n","\n","class GoEmotionClassifier(nn.Module):\n","    def __init__(self, n_train_steps, n_classes, do_prob, bert_model):\n","        super(GoEmotionClassifier, self).__init__()\n","        self.bert = bert_model\n","        self.dropout = nn.Dropout(do_prob)\n","        self.out = nn.Linear(768, n_classes)\n","        self.n_train_steps = n_train_steps\n","        self.step_scheduler_after = \"batch\"\n","\n","    def forward(self, ids, mask):\n","        output_1 = self.bert(ids, attention_mask=mask)[\"pooler_output\"]\n","        output_2 = self.dropout(output_1)\n","        output = self.out(output_2)\n","        return output\n","tokenizer = transformers.SqueezeBertTokenizer.from_pretrained(\"squeezebert/squeezebert-uncased\", do_lower_case=True)\n","\n","def build_dataset(tokenizer_max_len):\n","    train_dataset = GoEmotionDataset(train.text.tolist(), train[range(n_labels)].values.tolist(), tokenizer, tokenizer_max_len)\n","    valid_dataset = GoEmotionDataset(valid.text.tolist(), valid[range(n_labels)].values.tolist(), tokenizer, tokenizer_max_len)\n","    \n","    return train_dataset, valid_dataset\n","\n","def build_dataloader(train_dataset, valid_dataset, batch_size):\n","    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","    valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n","\n","    return train_data_loader, valid_data_loader\n","\n","def ret_model(n_train_steps, do_prob):\n","    model = GoEmotionClassifier(n_train_steps, n_labels, do_prob, bert_model=bert_model)\n","    return model\n","\n","\n","\n","bert_model = transformers.SqueezeBertModel.from_pretrained(\"squeezebert/squeezebert-uncased\")\n","\n","def ret_optimizer(model):\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\"]\n","    optimizer_parameters = [\n","        {\n","            \"params\": [\n","                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n","            ],\n","            \"weight_decay\": 0.001,\n","        },\n","        {\n","            \"params\": [\n","                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n","            ],\n","            \"weight_decay\": 0.0,\n","        },\n","    ]\n","    opt = AdamW(optimizer_parameters, lr=5e-5)\n","    return opt\n","\n","def ret_scheduler(optimizer, num_train_steps):\n","    sch = get_linear_schedule_with_warmup(\n","        optimizer, num_warmup_steps=0, num_training_steps=num_train_steps)\n","    return sch\n","\n","def loss_fn(outputs, labels):\n","    if labels is None:\n","        return None\n","    return nn.BCEWithLogitsLoss()(outputs, labels.float())\n","\n","def log_metrics(preds, labels):\n","    preds = torch.stack(preds)\n","    preds = preds.cpu().detach().numpy()\n","    labels = torch.stack(labels)\n","    labels = labels.cpu().detach().numpy()\n","    \n","    fpr_micro, tpr_micro, _ = metrics.roc_curve(labels.ravel(), preds.ravel())\n","    \n","    auc_micro = metrics.auc(fpr_micro, tpr_micro)\n","    return {\"auc_micro\": auc_micro}\n","def train_fn(data_loader, model, optimizer, device, scheduler):\n","\n","    train_loss = 0.0\n","    model.train()\n","    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n","        ids = d[\"ids\"]\n","        mask = d[\"mask\"]\n","        targets = d[\"labels\"]\n","\n","        ids = ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        targets = targets.to(device, dtype=torch.float)\n","\n","        optimizer.zero_grad()\n","        outputs = model(ids=ids, mask=mask)\n","\n","        loss = loss_fn(outputs, targets)\n","        loss.backward()\n","        train_loss += loss.item()\n","        optimizer.step()\n","        scheduler.step()\n","    return train_loss\n","    \n","\n","def eval_fn(data_loader, model, device):\n","    eval_loss = 0.0\n","    model.eval()\n","    fin_targets = []\n","    fin_outputs = []\n","    with torch.no_grad():\n","        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n","            ids = d[\"ids\"]\n","            mask = d[\"mask\"]\n","            targets = d[\"labels\"]\n","\n","            ids = ids.to(device, dtype=torch.long)\n","            mask = mask.to(device, dtype=torch.long)\n","            targets = targets.to(device, dtype=torch.float)\n","\n","            outputs = model(ids=ids, mask=mask)\n","            loss = loss_fn(outputs, targets)\n","            eval_loss += loss.item()\n","            fin_targets.extend(targets)\n","            fin_outputs.extend(torch.sigmoid(outputs))\n","    return eval_loss, fin_outputs, fin_targets\n","\n","def log_dataset(dataset_name):\n","    dataset = load_dataset(dataset_name)  # Load the dataset\n","    serialized_dataset = dataset.save_to_disk(\"dataset_directory\")  # Save the dataset to a directory\n","    mlflow.log_artifact(\"dataset_directory\")  # Log the serialized dataset\n","\n","\n","\n","def trainer():\n","    log_dataset(\"go_emotions\")\n","    go_emotions = load_dataset(\"go_emotions\")\n","    data = go_emotions.data\n","    \n","    train, valid, test = data[\"train\"].to_pandas(), data[\"validation\"].to_pandas(), data[\"test\"].to_pandas()\n","\n","    train_dataset, valid_dataset = build_dataset(40)\n","    train_data_loader, valid_data_loader = build_dataloader(train_dataset, valid_dataset, 64)\n","\n","    mlflow.log_param(\"train_dataset_size\", len(train))\n","    mlflow.log_param(\"valid_dataset_size\", len(valid))\n","    mlflow.log_param(\"test_dataset_size\", len(test))\n","\n","    mlflow.log_param(\"dataset_name\", \"Emotions\")\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    mlflow.log_param(\"device\", device)\n","    n_train_steps = int(len(train_dataset) / 64 * 10)\n","\n","    model = ret_model(n_train_steps, 0.3)\n","    optimizer = ret_optimizer(model)\n","    scheduler = ret_scheduler(optimizer, n_train_steps)\n","    model.to(device)\n","    model = nn.DataParallel(model)\n","    n_epochs = 2\n","\n","    best_val_loss = 100\n","#     with mlflow.start_run(experiment_id=experiment_id, run_name=\"Run 11\") as run:\n","#         mlflow.pytorch.autolog() \n","    for epoch in tqdm(range(n_epochs)):\n","        train_loss = train_fn(train_data_loader, model, optimizer, device, scheduler)\n","        eval_loss, preds, labels = eval_fn(valid_data_loader, model, device)\n","\n","        auc_score = log_metrics(preds, labels)[\"auc_micro\"]\n","        avg_train_loss, avg_val_loss = train_loss / len(train_data_loader), eval_loss / len(valid_data_loader)\n","        mlflow.log_metric(\"AUC\", auc_score)\n","        mlflow.log_metric(\"Avg Train Loss\", avg_train_loss)\n","        mlflow.log_metric(\"Avg Valid Loss\", avg_val_loss)\n","        if avg_val_loss < best_val_loss:\n","            best_val_loss = avg_val_loss\n","            torch.save(model.state_dict(), \"./best_model.pt\")  \n","            print(\"Model saved as current val_loss is: \", best_val_loss)\n","        script_dir = os.path.dirname(os.path.abspath('file'))\n","        models_dir = os.path.join(script_dir)\n","        conda_dir = os.path.join(script_dir)\n","        \n","        model_path = \"/kaggle/working/mlruns/best_model.pt\"\n","        mlflow.log_artifact(model_path, artifact_path=\"best_model\")\n","        mlflow.pytorch.log_model(\n","            pytorch_model= model,\n","            registered_model_name=\"best-base\",\n","            artifact_path=\"artifacts\",\n","#             input_example=df[['Title', 'Attributes']],\n","#             conda_env=conda_dir,\n","            code_paths=[models_dir]\n","    )"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-08-28T11:18:08.353420Z","iopub.status.busy":"2023-08-28T11:18:08.352540Z","iopub.status.idle":"2023-08-28T11:18:08.361995Z","shell.execute_reply":"2023-08-28T11:18:08.360298Z","shell.execute_reply.started":"2023-08-28T11:18:08.353370Z"},"trusted":true},"outputs":[],"source":["import mlflow.pytorch\n","\n","experiment_name = \"Distill Bert\"\n","experiment = mlflow.get_experiment_by_name(experiment_name)\n","if experiment is None:\n","    experiment_id = mlflow.create_experiment(experiment_name)\n","else:\n","    experiment_id = experiment.experiment_id\n","    \n","    \n","mlflow.set_tracking_uri(\"http://13.233.157.244:5001/\")\n","mlflow.pytorch.autolog()\n","\n","with mlflow.start_run(experiment_id=experiment_id, run_name=\"Run 13\"):\n","#     mlflow.pytorch.autolog()\n","     # Enable automatic logging for PyTorch\n","#     trained_model=trainer()\n","    trainer()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-08-28T11:18:12.397096Z","iopub.status.busy":"2023-08-28T11:18:12.396689Z","iopub.status.idle":"2023-08-28T11:18:12.401939Z","shell.execute_reply":"2023-08-28T11:18:12.400932Z","shell.execute_reply.started":"2023-08-28T11:18:12.397061Z"},"trusted":true},"outputs":[],"source":["mlflow.end_run()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2023-08-28T11:47:16.472651Z","iopub.status.busy":"2023-08-28T11:47:16.472225Z","iopub.status.idle":"2023-08-28T11:47:16.490977Z","shell.execute_reply":"2023-08-28T11:47:16.489841Z","shell.execute_reply.started":"2023-08-28T11:47:16.472615Z"},"trusted":true},"outputs":[],"source":["import optuna\n","import mlflow\n","import os\n","import torch\n","import torch.nn as nn\n","from tqdm import tqdm\n","\n","# Your existing functions and imports\n","\n","# Define the objective function for Optuna hyperparameter tuning\n","def objective(trial):\n","    with mlflow.start_run(experiment_id=experiment_id, run_name=\"Hyperparameter Tuning\") as run:\n","        log_dataset(\"go_emotions\")\n","        go_emotions = load_dataset(\"go_emotions\")\n","        data = go_emotions.data\n","        batch_size=64\n","        train, valid, test = data[\"train\"].to_pandas(), data[\"validation\"].to_pandas(), data[\"test\"].to_pandas()\n","\n","        train_dataset, valid_dataset = build_dataset(40)\n","        train_data_loader, valid_data_loader = build_dataloader(train_dataset, valid_dataset, batch_size)\n","\n","        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        mlflow.log_param(\"device\", device)\n","\n","        # Define hyperparameter search space\n","        learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)\n","        dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n","        do_prob = trial.suggest_uniform(\"do_prob\", 0.3, 0.5)\n","        n_epochs = trial.suggest_int(\"n_epochs\", 2, 4)\n","        # Update hyperparameters\n","    #     model = ret_model(n_train_steps, dropout_rate)  # Update your model with the new dropout_rate\n","    #     optimizer = ret_optimizer(model, learning_rate)  # Update your optimizer with the new learning_rate\n","\n","        n_train_steps = int(len(train_dataset) / 64 * 10)\n","\n","        model = ret_model(n_train_steps, do_prob)\n","        optimizer = ret_optimizer(model)\n","        scheduler = ret_scheduler(optimizer, n_train_steps)\n","        model.to(device)\n","        model = nn.DataParallel(model)\n","\n","        best_val_loss = 100\n","\n","        # Rest of your training loop\n","        for epoch in tqdm(range(n_epochs)):\n","            train_loss = train_fn(train_data_loader, model, optimizer, device, scheduler)\n","            eval_loss, preds, labels = eval_fn(valid_data_loader, model, device)\n","\n","            auc_score = log_metrics(preds, labels)[\"auc_micro\"]\n","            avg_train_loss, avg_val_loss = train_loss / len(train_data_loader), eval_loss / len(valid_data_loader)\n","            mlflow.log_metric(\"AUC\", auc_score)\n","            mlflow.log_metric(\"Avg Train Loss\", avg_train_loss)\n","            mlflow.log_metric(\"Avg Valid Loss\", avg_val_loss)\n","            if avg_val_loss < best_val_loss:\n","                best_val_loss = avg_val_loss\n","                torch.save(model.state_dict(), \"./best_model.pt\")  \n","                print(\"Model saved as current val_loss is: \", best_val_loss)\n","                model_path = \"/kaggle/working/best_model.pt\"\n","                mlflow.log_artifact(model_path, artifact_path=\"best_model\")\n","            script_dir = os.path.dirname(os.path.abspath('file'))\n","            models_dir = os.path.join(script_dir, \"models\")\n","            conda_dir = os.path.join(script_dir, \"dependencies\", \"conda.yaml\")\n","\n","            # Log the best model with Optuna hyperparameters\n","            mlflow.pytorch.log_model(\n","                pytorch_model=model,\n","                registered_model_name=\"best-base\",\n","                artifact_path=\"artifacts\",\n","            )\n","\n","    # Return the value to minimize (e.g., validation loss)\n","    return best_val_loss\n","\n","# Main training code\n","def trainer():\n","    # Start Optuna hyperparameter tuning\n","    study = optuna.create_study(direction=\"minimize\")\n","    study.optimize(objective, n_trials=30,show_progress_bar=False)  \n","\n","    best_params = study.best_params\n","    best_metric = study.best_value\n","\n","    for param_name, param_value in best_params.items():\n","        mlflow.log_param(param_name, param_value)\n","\n","    mlflow.log_metric(\"best_metric\", best_metric)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-28T11:47:18.831862Z","iopub.status.busy":"2023-08-28T11:47:18.831444Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2023-08-28 11:47:19,304] A new study created in memory with name: no-name-a44d4a31-d307-41cd-83b8-c42259ea859d\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"54b45943413342cf8b132c075fddcd6f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e4594f826e64ad5a3579bf6c1332a84","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/2 [00:00<?, ?it/s]\n","  0%|          | 0/679 [00:00<?, ?it/s]\u001b[A\n","  0%|          | 1/679 [00:00<05:40,  1.99it/s]\u001b[A\n","  0%|          | 2/679 [00:00<04:24,  2.55it/s]\u001b[A\n","  0%|          | 3/679 [00:01<04:00,  2.81it/s]\u001b[A\n","  1%|          | 4/679 [00:01<03:44,  3.00it/s]\u001b[A\n","  1%|          | 5/679 [00:01<03:36,  3.11it/s]\u001b[A\n","  1%|          | 6/679 [00:02<03:32,  3.17it/s]\u001b[A\n","  1%|          | 7/679 [00:02<03:30,  3.19it/s]\u001b[A\n","  1%|          | 8/679 [00:02<03:28,  3.22it/s]\u001b[A\n","  1%|▏         | 9/679 [00:02<03:27,  3.23it/s]\u001b[A\n","  1%|▏         | 10/679 [00:03<03:25,  3.26it/s]\u001b[A\n","  2%|▏         | 11/679 [00:03<03:24,  3.26it/s]\u001b[A\n","  2%|▏         | 12/679 [00:03<03:23,  3.28it/s]\u001b[A\n","  2%|▏         | 13/679 [00:04<03:22,  3.29it/s]\u001b[A\n","  2%|▏         | 14/679 [00:04<03:21,  3.30it/s]\u001b[A\n","  2%|▏         | 15/679 [00:04<03:22,  3.28it/s]\u001b[A\n","  2%|▏         | 16/679 [00:05<03:22,  3.28it/s]\u001b[A\n","  3%|▎         | 17/679 [00:05<03:20,  3.30it/s]\u001b[A\n","  3%|▎         | 18/679 [00:05<03:23,  3.25it/s]\u001b[A\n","  3%|▎         | 19/679 [00:06<03:22,  3.26it/s]\u001b[A\n","  3%|▎         | 20/679 [00:06<03:21,  3.27it/s]\u001b[A\n","  3%|▎         | 21/679 [00:06<03:21,  3.27it/s]\u001b[A\n","  3%|▎         | 22/679 [00:06<03:27,  3.17it/s]\u001b[A\n","  3%|▎         | 23/679 [00:07<03:30,  3.12it/s]\u001b[A\n","  4%|▎         | 24/679 [00:07<03:27,  3.15it/s]\u001b[A\n","  4%|▎         | 25/679 [00:07<03:25,  3.18it/s]\u001b[A\n","  4%|▍         | 26/679 [00:08<03:23,  3.21it/s]\u001b[A\n","  4%|▍         | 27/679 [00:08<03:24,  3.19it/s]\u001b[A\n","  4%|▍         | 28/679 [00:08<03:22,  3.21it/s]\u001b[A\n","  4%|▍         | 29/679 [00:09<03:23,  3.20it/s]\u001b[A\n","  4%|▍         | 30/679 [00:09<03:20,  3.24it/s]\u001b[A\n","  5%|▍         | 31/679 [00:09<03:19,  3.24it/s]\u001b[A\n","  5%|▍         | 32/679 [00:10<03:19,  3.25it/s]\u001b[A\n","  5%|▍         | 33/679 [00:10<03:18,  3.25it/s]\u001b[A\n","  5%|▌         | 34/679 [00:10<03:19,  3.24it/s]\u001b[A\n","  5%|▌         | 35/679 [00:10<03:18,  3.25it/s]\u001b[A\n","  5%|▌         | 36/679 [00:11<03:17,  3.25it/s]\u001b[A\n","  5%|▌         | 37/679 [00:11<03:18,  3.23it/s]\u001b[A\n","  6%|▌         | 38/679 [00:11<03:18,  3.23it/s]\u001b[A\n","  6%|▌         | 39/679 [00:12<03:17,  3.25it/s]\u001b[A\n","  6%|▌         | 40/679 [00:12<03:17,  3.24it/s]\u001b[A\n","  6%|▌         | 41/679 [00:12<03:16,  3.24it/s]\u001b[A\n","  6%|▌         | 42/679 [00:13<03:18,  3.21it/s]\u001b[A\n","  6%|▋         | 43/679 [00:13<03:18,  3.20it/s]\u001b[A\n","  6%|▋         | 44/679 [00:13<03:18,  3.19it/s]\u001b[A\n","  7%|▋         | 45/679 [00:14<03:18,  3.20it/s]\u001b[A\n","  7%|▋         | 46/679 [00:14<03:15,  3.23it/s]\u001b[A\n","  7%|▋         | 47/679 [00:14<03:17,  3.20it/s]\u001b[A\n","  7%|▋         | 48/679 [00:15<03:16,  3.21it/s]\u001b[A\n","  7%|▋         | 49/679 [00:15<03:16,  3.21it/s]\u001b[A\n","  7%|▋         | 50/679 [00:15<03:14,  3.24it/s]\u001b[A\n","  8%|▊         | 51/679 [00:15<03:12,  3.26it/s]\u001b[A\n","  8%|▊         | 52/679 [00:16<03:13,  3.24it/s]\u001b[A\n","  8%|▊         | 53/679 [00:16<03:14,  3.22it/s]\u001b[A\n","  8%|▊         | 54/679 [00:16<03:13,  3.23it/s]\u001b[A\n","  8%|▊         | 55/679 [00:17<03:13,  3.22it/s]\u001b[A\n","  8%|▊         | 56/679 [00:17<03:11,  3.25it/s]\u001b[A\n","  8%|▊         | 57/679 [00:17<03:10,  3.26it/s]\u001b[A\n","  9%|▊         | 58/679 [00:18<03:09,  3.28it/s]\u001b[A\n","  9%|▊         | 59/679 [00:18<03:08,  3.29it/s]\u001b[A\n","  9%|▉         | 60/679 [00:18<03:08,  3.29it/s]\u001b[A\n","  9%|▉         | 61/679 [00:19<03:08,  3.27it/s]\u001b[A\n","  9%|▉         | 62/679 [00:19<03:07,  3.28it/s]\u001b[A\n","  9%|▉         | 63/679 [00:19<03:08,  3.26it/s]\u001b[A\n","  9%|▉         | 64/679 [00:19<03:09,  3.25it/s]\u001b[A\n"," 10%|▉         | 65/679 [00:20<03:07,  3.27it/s]\u001b[A\n"," 10%|▉         | 66/679 [00:20<03:08,  3.25it/s]\u001b[A\n"," 10%|▉         | 67/679 [00:20<03:07,  3.27it/s]\u001b[A\n"," 10%|█         | 68/679 [00:21<03:08,  3.25it/s]\u001b[A\n"," 10%|█         | 69/679 [00:21<03:07,  3.26it/s]\u001b[A\n"," 10%|█         | 70/679 [00:21<03:07,  3.25it/s]\u001b[A\n"," 10%|█         | 71/679 [00:22<03:06,  3.26it/s]\u001b[A\n"," 11%|█         | 72/679 [00:22<03:05,  3.26it/s]\u001b[A\n"," 11%|█         | 73/679 [00:22<03:06,  3.25it/s]\u001b[A\n"," 11%|█         | 74/679 [00:23<03:06,  3.25it/s]\u001b[A\n"," 11%|█         | 75/679 [00:23<03:04,  3.27it/s]\u001b[A\n"," 11%|█         | 76/679 [00:23<03:04,  3.27it/s]\u001b[A\n"," 11%|█▏        | 77/679 [00:23<03:04,  3.26it/s]\u001b[A\n"," 11%|█▏        | 78/679 [00:24<03:04,  3.25it/s]\u001b[A\n"," 12%|█▏        | 79/679 [00:24<03:07,  3.21it/s]\u001b[A\n"," 12%|█▏        | 80/679 [00:24<03:12,  3.12it/s]\u001b[A\n"," 12%|█▏        | 81/679 [00:25<03:15,  3.05it/s]\u001b[A\n"," 12%|█▏        | 82/679 [00:25<03:17,  3.03it/s]\u001b[A\n"," 12%|█▏        | 83/679 [00:25<03:19,  2.98it/s]\u001b[A\n"," 12%|█▏        | 84/679 [00:26<03:22,  2.94it/s]\u001b[A\n"," 13%|█▎        | 85/679 [00:26<03:17,  3.00it/s]\u001b[A\n"," 13%|█▎        | 86/679 [00:26<03:19,  2.97it/s]\u001b[A\n"," 13%|█▎        | 87/679 [00:27<03:19,  2.97it/s]\u001b[A\n"," 13%|█▎        | 88/679 [00:27<03:13,  3.06it/s]\u001b[A\n"," 13%|█▎        | 89/679 [00:27<03:10,  3.10it/s]\u001b[A\n"," 13%|█▎        | 90/679 [00:28<03:08,  3.13it/s]\u001b[A\n"," 13%|█▎        | 91/679 [00:28<03:05,  3.18it/s]\u001b[A\n"," 14%|█▎        | 92/679 [00:28<03:03,  3.20it/s]\u001b[A\n"," 14%|█▎        | 93/679 [00:29<03:02,  3.21it/s]\u001b[A\n"," 14%|█▍        | 94/679 [00:29<03:01,  3.23it/s]\u001b[A\n"," 14%|█▍        | 95/679 [00:29<02:59,  3.25it/s]\u001b[A\n"," 14%|█▍        | 96/679 [00:30<02:59,  3.25it/s]\u001b[A\n"," 14%|█▍        | 97/679 [00:30<02:59,  3.24it/s]\u001b[A\n"," 14%|█▍        | 98/679 [00:30<02:59,  3.23it/s]\u001b[A\n"," 15%|█▍        | 99/679 [00:30<03:00,  3.21it/s]\u001b[A\n"," 15%|█▍        | 100/679 [00:31<03:00,  3.21it/s]\u001b[A\n"," 15%|█▍        | 101/679 [00:31<02:58,  3.23it/s]\u001b[A\n"," 15%|█▌        | 102/679 [00:31<02:57,  3.25it/s]\u001b[A\n"," 15%|█▌        | 103/679 [00:32<02:56,  3.26it/s]\u001b[A\n"," 15%|█▌        | 104/679 [00:32<02:56,  3.25it/s]\u001b[A\n"," 15%|█▌        | 105/679 [00:32<02:55,  3.27it/s]\u001b[A\n"," 16%|█▌        | 106/679 [00:33<02:54,  3.28it/s]\u001b[A\n"," 16%|█▌        | 107/679 [00:33<02:55,  3.27it/s]\u001b[A\n"," 16%|█▌        | 108/679 [00:33<02:54,  3.27it/s]\u001b[A\n"," 16%|█▌        | 109/679 [00:34<02:54,  3.26it/s]\u001b[A\n"," 16%|█▌        | 110/679 [00:34<02:54,  3.27it/s]\u001b[A\n"," 16%|█▋        | 111/679 [00:34<02:53,  3.27it/s]\u001b[A\n"," 16%|█▋        | 112/679 [00:34<02:54,  3.26it/s]\u001b[A\n"," 17%|█▋        | 113/679 [00:35<02:53,  3.27it/s]\u001b[A\n"," 17%|█▋        | 114/679 [00:35<02:53,  3.26it/s]\u001b[A\n"," 17%|█▋        | 115/679 [00:35<02:53,  3.24it/s]\u001b[A\n"," 17%|█▋        | 116/679 [00:36<02:53,  3.24it/s]\u001b[A\n"," 17%|█▋        | 117/679 [00:36<02:54,  3.22it/s]\u001b[A\n"," 17%|█▋        | 118/679 [00:36<02:55,  3.20it/s]\u001b[A\n"," 18%|█▊        | 119/679 [00:37<02:54,  3.20it/s]\u001b[A\n"," 18%|█▊        | 120/679 [00:37<02:53,  3.22it/s]\u001b[A\n"," 18%|█▊        | 121/679 [00:37<02:52,  3.24it/s]\u001b[A\n"," 18%|█▊        | 122/679 [00:38<02:54,  3.20it/s]\u001b[A\n"," 18%|█▊        | 123/679 [00:38<02:52,  3.23it/s]\u001b[A\n"," 18%|█▊        | 124/679 [00:38<02:52,  3.22it/s]\u001b[A\n"," 18%|█▊        | 125/679 [00:38<02:51,  3.23it/s]\u001b[A\n"," 19%|█▊        | 126/679 [00:39<02:50,  3.25it/s]\u001b[A\n"," 19%|█▊        | 127/679 [00:39<02:49,  3.25it/s]\u001b[A\n"," 19%|█▉        | 128/679 [00:39<02:49,  3.26it/s]\u001b[A\n"," 19%|█▉        | 129/679 [00:40<02:48,  3.26it/s]\u001b[A\n"," 19%|█▉        | 130/679 [00:40<02:49,  3.23it/s]\u001b[A\n"," 19%|█▉        | 131/679 [00:40<02:48,  3.25it/s]\u001b[A\n"," 19%|█▉        | 132/679 [00:41<02:47,  3.26it/s]\u001b[A\n"," 20%|█▉        | 133/679 [00:41<02:47,  3.26it/s]\u001b[A\n"," 20%|█▉        | 134/679 [00:41<02:46,  3.28it/s]\u001b[A\n"," 20%|█▉        | 135/679 [00:42<02:46,  3.28it/s]\u001b[A\n"," 20%|██        | 136/679 [00:42<02:48,  3.23it/s]\u001b[A\n"," 20%|██        | 137/679 [00:42<02:46,  3.25it/s]\u001b[A\n"," 20%|██        | 138/679 [00:42<02:46,  3.25it/s]\u001b[A\n"," 20%|██        | 139/679 [00:43<02:45,  3.27it/s]\u001b[A\n"," 21%|██        | 140/679 [00:43<02:45,  3.25it/s]\u001b[A\n"," 21%|██        | 141/679 [00:43<02:45,  3.25it/s]\u001b[A\n"," 21%|██        | 142/679 [00:44<02:44,  3.27it/s]\u001b[A\n"," 21%|██        | 143/679 [00:44<02:43,  3.27it/s]\u001b[A\n"," 21%|██        | 144/679 [00:44<02:43,  3.27it/s]\u001b[A\n"," 21%|██▏       | 145/679 [00:45<02:44,  3.25it/s]\u001b[A\n"," 22%|██▏       | 146/679 [00:45<02:44,  3.23it/s]\u001b[A\n"," 22%|██▏       | 147/679 [00:45<02:44,  3.24it/s]\u001b[A\n"," 22%|██▏       | 148/679 [00:46<02:43,  3.24it/s]\u001b[A\n"," 22%|██▏       | 149/679 [00:46<02:43,  3.23it/s]\u001b[A\n"," 22%|██▏       | 150/679 [00:46<02:42,  3.25it/s]\u001b[A\n"," 22%|██▏       | 151/679 [00:47<02:46,  3.17it/s]\u001b[A\n"," 22%|██▏       | 152/679 [00:47<02:46,  3.17it/s]\u001b[A\n"," 23%|██▎       | 153/679 [00:47<02:44,  3.19it/s]\u001b[A\n"," 23%|██▎       | 154/679 [00:47<02:43,  3.20it/s]\u001b[A\n"," 23%|██▎       | 155/679 [00:48<02:42,  3.23it/s]\u001b[A\n"," 23%|██▎       | 156/679 [00:48<02:41,  3.24it/s]\u001b[A\n"," 23%|██▎       | 157/679 [00:48<02:40,  3.26it/s]\u001b[A\n"," 23%|██▎       | 158/679 [00:49<02:38,  3.28it/s]\u001b[A\n"," 23%|██▎       | 159/679 [00:49<02:40,  3.25it/s]\u001b[A\n"," 24%|██▎       | 160/679 [00:49<02:39,  3.26it/s]\u001b[A\n"," 24%|██▎       | 161/679 [00:50<02:38,  3.27it/s]\u001b[A\n"," 24%|██▍       | 162/679 [00:50<02:37,  3.27it/s]\u001b[A\n"," 24%|██▍       | 163/679 [00:50<02:38,  3.26it/s]\u001b[A\n"," 24%|██▍       | 164/679 [00:51<02:38,  3.24it/s]\u001b[A\n"," 24%|██▍       | 165/679 [00:51<02:38,  3.24it/s]\u001b[A\n"," 24%|██▍       | 166/679 [00:51<02:37,  3.26it/s]\u001b[A\n"," 25%|██▍       | 167/679 [00:51<02:36,  3.27it/s]\u001b[A\n"," 25%|██▍       | 168/679 [00:52<02:36,  3.26it/s]\u001b[A\n"," 25%|██▍       | 169/679 [00:52<02:36,  3.26it/s]\u001b[A\n"," 25%|██▌       | 170/679 [00:52<02:35,  3.27it/s]\u001b[A\n"," 25%|██▌       | 171/679 [00:53<02:36,  3.25it/s]\u001b[A\n"," 25%|██▌       | 172/679 [00:53<02:36,  3.23it/s]\u001b[A\n"," 25%|██▌       | 173/679 [00:53<02:35,  3.25it/s]\u001b[A\n"," 26%|██▌       | 174/679 [00:54<02:35,  3.25it/s]\u001b[A\n"," 26%|██▌       | 175/679 [00:54<02:35,  3.25it/s]\u001b[A\n"," 26%|██▌       | 176/679 [00:54<02:35,  3.23it/s]\u001b[A\n"," 26%|██▌       | 177/679 [00:55<02:35,  3.23it/s]\u001b[A\n"," 26%|██▌       | 178/679 [00:55<02:35,  3.22it/s]\u001b[A\n"," 26%|██▋       | 179/679 [00:55<02:33,  3.25it/s]\u001b[A\n"," 27%|██▋       | 180/679 [00:55<02:33,  3.26it/s]\u001b[A\n"," 27%|██▋       | 181/679 [00:56<02:33,  3.25it/s]\u001b[A\n"," 27%|██▋       | 182/679 [00:56<02:33,  3.24it/s]\u001b[A\n"," 27%|██▋       | 183/679 [00:56<02:42,  3.04it/s]\u001b[A\n"," 27%|██▋       | 184/679 [00:57<02:49,  2.93it/s]\u001b[A\n"," 27%|██▋       | 185/679 [00:57<02:50,  2.90it/s]\u001b[A\n"," 27%|██▋       | 186/679 [00:57<02:50,  2.89it/s]\u001b[A\n"," 28%|██▊       | 187/679 [00:58<02:44,  2.99it/s]\u001b[A\n"," 28%|██▊       | 188/679 [00:58<02:40,  3.06it/s]\u001b[A\n"," 28%|██▊       | 189/679 [00:58<02:36,  3.14it/s]\u001b[A\n"," 28%|██▊       | 190/679 [00:59<02:32,  3.20it/s]\u001b[A\n"," 28%|██▊       | 191/679 [00:59<02:30,  3.24it/s]\u001b[A\n"," 28%|██▊       | 192/679 [00:59<02:30,  3.24it/s]\u001b[A\n"," 28%|██▊       | 193/679 [01:00<02:28,  3.26it/s]\u001b[A\n"," 29%|██▊       | 194/679 [01:00<02:29,  3.23it/s]\u001b[A\n"," 29%|██▊       | 195/679 [01:00<02:28,  3.26it/s]\u001b[A\n"," 29%|██▉       | 196/679 [01:01<02:28,  3.25it/s]\u001b[A\n"," 29%|██▉       | 197/679 [01:01<02:28,  3.25it/s]\u001b[A\n"," 29%|██▉       | 198/679 [01:01<02:27,  3.26it/s]\u001b[A\n"," 29%|██▉       | 199/679 [01:01<02:27,  3.26it/s]\u001b[A\n"," 29%|██▉       | 200/679 [01:02<02:25,  3.28it/s]\u001b[A\n"," 30%|██▉       | 201/679 [01:02<02:26,  3.27it/s]\u001b[A\n"," 30%|██▉       | 202/679 [01:02<02:25,  3.27it/s]\u001b[A\n"," 30%|██▉       | 203/679 [01:03<02:26,  3.26it/s]\u001b[A\n"," 30%|███       | 204/679 [01:03<02:24,  3.28it/s]\u001b[A\n"," 30%|███       | 205/679 [01:03<02:25,  3.26it/s]\u001b[A\n"," 30%|███       | 206/679 [01:04<02:24,  3.27it/s]\u001b[A\n"," 30%|███       | 207/679 [01:04<02:25,  3.24it/s]\u001b[A\n"," 31%|███       | 208/679 [01:04<02:25,  3.25it/s]\u001b[A\n"," 31%|███       | 209/679 [01:05<02:24,  3.26it/s]\u001b[A\n"," 31%|███       | 210/679 [01:05<02:24,  3.25it/s]\u001b[A\n"," 31%|███       | 211/679 [01:05<02:23,  3.27it/s]\u001b[A\n"," 31%|███       | 212/679 [01:05<02:22,  3.29it/s]\u001b[A\n"," 31%|███▏      | 213/679 [01:06<02:21,  3.29it/s]\u001b[A\n"," 32%|███▏      | 214/679 [01:06<02:21,  3.28it/s]\u001b[A\n"," 32%|███▏      | 215/679 [01:06<02:22,  3.26it/s]\u001b[A\n"," 32%|███▏      | 216/679 [01:07<02:22,  3.26it/s]\u001b[A\n"," 32%|███▏      | 217/679 [01:07<02:22,  3.25it/s]\u001b[A\n"," 32%|███▏      | 218/679 [01:07<02:22,  3.22it/s]\u001b[A\n"," 32%|███▏      | 219/679 [01:08<02:22,  3.24it/s]\u001b[A\n"," 32%|███▏      | 220/679 [01:08<02:21,  3.23it/s]\u001b[A\n"," 33%|███▎      | 221/679 [01:08<02:21,  3.23it/s]\u001b[A\n"," 33%|███▎      | 222/679 [01:09<02:22,  3.22it/s]\u001b[A\n"," 33%|███▎      | 223/679 [01:09<02:22,  3.20it/s]\u001b[A\n"," 33%|███▎      | 224/679 [01:09<02:20,  3.23it/s]\u001b[A\n"," 33%|███▎      | 225/679 [01:09<02:20,  3.23it/s]\u001b[A\n"," 33%|███▎      | 226/679 [01:10<02:20,  3.23it/s]\u001b[A\n"," 33%|███▎      | 227/679 [01:10<02:19,  3.24it/s]\u001b[A\n"," 34%|███▎      | 228/679 [01:10<02:18,  3.25it/s]\u001b[A\n"," 34%|███▎      | 229/679 [01:11<02:17,  3.26it/s]\u001b[A\n"," 34%|███▍      | 230/679 [01:11<02:17,  3.26it/s]\u001b[A\n"," 34%|███▍      | 231/679 [01:11<02:17,  3.27it/s]\u001b[A\n"," 34%|███▍      | 232/679 [01:12<03:54,  1.90it/s]\u001b[A\n"," 34%|███▍      | 233/679 [01:13<03:24,  2.18it/s]\u001b[A\n"," 34%|███▍      | 234/679 [01:13<03:04,  2.41it/s]\u001b[A\n"," 35%|███▍      | 235/679 [01:13<02:48,  2.63it/s]\u001b[A\n"," 35%|███▍      | 236/679 [01:14<02:38,  2.80it/s]\u001b[A\n"," 35%|███▍      | 237/679 [01:14<02:31,  2.92it/s]\u001b[A\n"," 35%|███▌      | 238/679 [01:14<02:26,  3.01it/s]\u001b[A\n"," 35%|███▌      | 239/679 [01:14<02:23,  3.07it/s]\u001b[A\n"," 35%|███▌      | 240/679 [01:15<02:20,  3.12it/s]\u001b[A\n"," 35%|███▌      | 241/679 [01:15<02:19,  3.15it/s]\u001b[A\n"," 36%|███▌      | 242/679 [01:15<02:17,  3.18it/s]\u001b[A\n"," 36%|███▌      | 243/679 [01:16<02:16,  3.19it/s]\u001b[A\n"," 36%|███▌      | 244/679 [01:16<02:15,  3.22it/s]\u001b[A\n"," 36%|███▌      | 245/679 [01:16<02:13,  3.24it/s]\u001b[A\n"," 36%|███▌      | 246/679 [01:17<02:13,  3.24it/s]\u001b[A\n"," 36%|███▋      | 247/679 [01:17<02:12,  3.25it/s]\u001b[A\n"," 37%|███▋      | 248/679 [01:17<02:11,  3.28it/s]\u001b[A\n"," 37%|███▋      | 249/679 [01:18<02:10,  3.29it/s]\u001b[A\n"," 37%|███▋      | 250/679 [01:18<02:10,  3.29it/s]\u001b[A\n"," 37%|███▋      | 251/679 [01:18<02:10,  3.28it/s]\u001b[A\n"," 37%|███▋      | 252/679 [01:18<02:10,  3.27it/s]\u001b[A\n"," 37%|███▋      | 253/679 [01:19<02:09,  3.28it/s]\u001b[A\n"," 37%|███▋      | 254/679 [01:19<02:09,  3.28it/s]\u001b[A\n"," 38%|███▊      | 255/679 [01:19<02:09,  3.28it/s]\u001b[A\n"," 38%|███▊      | 256/679 [01:20<02:09,  3.26it/s]\u001b[A\n"," 38%|███▊      | 257/679 [01:20<02:09,  3.27it/s]\u001b[A\n"," 38%|███▊      | 258/679 [01:20<02:07,  3.29it/s]\u001b[A\n"," 38%|███▊      | 259/679 [01:21<02:07,  3.30it/s]\u001b[A\n"," 38%|███▊      | 260/679 [01:21<02:06,  3.31it/s]\u001b[A\n"," 38%|███▊      | 261/679 [01:21<02:07,  3.29it/s]\u001b[A\n"," 39%|███▊      | 262/679 [01:22<02:07,  3.26it/s]\u001b[A\n"," 39%|███▊      | 263/679 [01:22<02:08,  3.23it/s]\u001b[A\n"," 39%|███▉      | 264/679 [01:22<02:08,  3.23it/s]\u001b[A\n"," 39%|███▉      | 265/679 [01:22<02:07,  3.26it/s]\u001b[A\n"," 39%|███▉      | 266/679 [01:23<02:06,  3.26it/s]\u001b[A\n"," 39%|███▉      | 267/679 [01:23<02:05,  3.27it/s]\u001b[A\n"," 39%|███▉      | 268/679 [01:23<02:05,  3.28it/s]\u001b[A\n"," 40%|███▉      | 269/679 [01:24<02:05,  3.27it/s]\u001b[A\n"," 40%|███▉      | 270/679 [01:24<02:05,  3.26it/s]\u001b[A\n"," 40%|███▉      | 271/679 [01:24<02:04,  3.26it/s]\u001b[A\n"," 40%|████      | 272/679 [01:25<02:04,  3.26it/s]\u001b[A\n"," 40%|████      | 273/679 [01:25<02:03,  3.29it/s]\u001b[A\n"," 40%|████      | 274/679 [01:25<02:03,  3.28it/s]\u001b[A\n"," 41%|████      | 275/679 [01:25<02:03,  3.28it/s]\u001b[A\n"," 41%|████      | 276/679 [01:26<02:02,  3.30it/s]\u001b[A\n"," 41%|████      | 277/679 [01:26<02:01,  3.31it/s]\u001b[A\n"," 41%|████      | 278/679 [01:26<02:03,  3.23it/s]\u001b[A\n"," 41%|████      | 279/679 [01:27<02:05,  3.18it/s]\u001b[A\n"," 41%|████      | 280/679 [01:27<02:03,  3.22it/s]\u001b[A\n"," 41%|████▏     | 281/679 [01:27<02:04,  3.20it/s]\u001b[A\n"," 42%|████▏     | 282/679 [01:28<02:02,  3.23it/s]\u001b[A\n"," 42%|████▏     | 283/679 [01:28<02:03,  3.20it/s]\u001b[A\n"," 42%|████▏     | 284/679 [01:28<02:04,  3.18it/s]\u001b[A\n"," 42%|████▏     | 285/679 [01:29<02:09,  3.03it/s]\u001b[A\n"," 42%|████▏     | 286/679 [01:29<02:13,  2.94it/s]\u001b[A\n"," 42%|████▏     | 287/679 [01:29<02:10,  2.99it/s]\u001b[A\n"," 42%|████▏     | 288/679 [01:30<02:07,  3.08it/s]\u001b[A\n"," 43%|████▎     | 289/679 [01:30<02:03,  3.15it/s]\u001b[A\n"," 43%|████▎     | 290/679 [01:30<02:02,  3.17it/s]\u001b[A\n"," 43%|████▎     | 291/679 [01:31<02:02,  3.16it/s]\u001b[A\n"," 43%|████▎     | 292/679 [01:31<02:01,  3.19it/s]\u001b[A\n"," 43%|████▎     | 293/679 [01:31<01:59,  3.23it/s]\u001b[A\n"," 43%|████▎     | 294/679 [01:31<01:58,  3.24it/s]\u001b[A\n"," 43%|████▎     | 295/679 [01:32<01:57,  3.27it/s]\u001b[A\n"," 44%|████▎     | 296/679 [01:32<01:57,  3.27it/s]\u001b[A\n"," 44%|████▎     | 297/679 [01:32<01:56,  3.27it/s]\u001b[A\n"," 44%|████▍     | 298/679 [01:33<01:56,  3.27it/s]\u001b[A\n"," 44%|████▍     | 299/679 [01:33<01:56,  3.26it/s]\u001b[A\n"," 44%|████▍     | 300/679 [01:33<01:56,  3.25it/s]\u001b[A\n"," 44%|████▍     | 301/679 [01:34<01:56,  3.25it/s]\u001b[A\n"," 44%|████▍     | 302/679 [01:34<01:56,  3.22it/s]\u001b[A\n"," 45%|████▍     | 303/679 [01:34<01:56,  3.23it/s]\u001b[A\n"," 45%|████▍     | 304/679 [01:35<01:55,  3.26it/s]\u001b[A\n"," 45%|████▍     | 305/679 [01:35<01:53,  3.29it/s]\u001b[A\n"," 45%|████▌     | 306/679 [01:35<01:52,  3.30it/s]\u001b[A\n"," 45%|████▌     | 307/679 [01:35<01:53,  3.27it/s]\u001b[A\n"," 45%|████▌     | 308/679 [01:36<01:53,  3.26it/s]\u001b[A\n"," 46%|████▌     | 309/679 [01:36<01:53,  3.25it/s]\u001b[A\n"," 46%|████▌     | 310/679 [01:36<01:53,  3.24it/s]\u001b[A\n"," 46%|████▌     | 311/679 [01:37<01:56,  3.16it/s]\u001b[A\n"," 46%|████▌     | 312/679 [01:37<01:54,  3.19it/s]\u001b[A\n"," 46%|████▌     | 313/679 [01:37<01:53,  3.22it/s]\u001b[A\n"," 46%|████▌     | 314/679 [01:38<01:52,  3.25it/s]\u001b[A\n"," 46%|████▋     | 315/679 [01:38<01:51,  3.27it/s]\u001b[A\n"," 47%|████▋     | 316/679 [01:38<01:50,  3.28it/s]\u001b[A\n"," 47%|████▋     | 317/679 [01:39<01:50,  3.28it/s]\u001b[A\n"," 47%|████▋     | 318/679 [01:39<01:50,  3.28it/s]\u001b[A\n"," 47%|████▋     | 319/679 [01:39<01:49,  3.29it/s]\u001b[A\n"," 47%|████▋     | 320/679 [01:39<01:49,  3.28it/s]\u001b[A\n"," 47%|████▋     | 321/679 [01:40<01:49,  3.27it/s]\u001b[A\n"," 47%|████▋     | 322/679 [01:40<01:50,  3.24it/s]\u001b[A\n"," 48%|████▊     | 323/679 [01:40<01:50,  3.23it/s]\u001b[A\n"," 48%|████▊     | 324/679 [01:41<01:50,  3.22it/s]\u001b[A\n"," 48%|████▊     | 325/679 [01:41<01:49,  3.22it/s]\u001b[A\n"," 48%|████▊     | 326/679 [01:41<01:49,  3.23it/s]\u001b[A\n"," 48%|████▊     | 327/679 [01:42<01:49,  3.23it/s]\u001b[A\n"," 48%|████▊     | 328/679 [01:42<01:48,  3.24it/s]\u001b[A\n"," 48%|████▊     | 329/679 [01:42<01:48,  3.22it/s]\u001b[A\n"," 49%|████▊     | 330/679 [01:43<01:48,  3.23it/s]\u001b[A\n"," 49%|████▊     | 331/679 [01:43<01:47,  3.22it/s]\u001b[A\n"," 49%|████▉     | 332/679 [01:43<01:47,  3.22it/s]\u001b[A\n"," 49%|████▉     | 333/679 [01:44<01:47,  3.22it/s]\u001b[A\n"," 49%|████▉     | 334/679 [01:44<01:47,  3.22it/s]\u001b[A\n"," 49%|████▉     | 335/679 [01:44<01:46,  3.24it/s]\u001b[A\n"," 49%|████▉     | 336/679 [01:44<01:45,  3.27it/s]\u001b[A\n"," 50%|████▉     | 337/679 [01:45<01:44,  3.26it/s]\u001b[A\n"," 50%|████▉     | 338/679 [01:45<01:44,  3.28it/s]\u001b[A\n"," 50%|████▉     | 339/679 [01:45<01:43,  3.29it/s]\u001b[A\n"," 50%|█████     | 340/679 [01:46<01:43,  3.26it/s]\u001b[A\n"," 50%|█████     | 341/679 [01:46<01:43,  3.25it/s]\u001b[A\n"," 50%|█████     | 342/679 [01:46<01:43,  3.26it/s]\u001b[A\n"," 51%|█████     | 343/679 [01:47<01:43,  3.25it/s]\u001b[A\n"," 51%|█████     | 344/679 [01:47<01:42,  3.27it/s]\u001b[A\n"," 51%|█████     | 345/679 [01:47<01:42,  3.27it/s]\u001b[A\n"," 51%|█████     | 346/679 [01:47<01:41,  3.27it/s]\u001b[A\n"," 51%|█████     | 347/679 [01:48<01:41,  3.26it/s]\u001b[A\n"," 51%|█████▏    | 348/679 [01:48<01:41,  3.27it/s]\u001b[A\n"," 51%|█████▏    | 349/679 [01:48<01:41,  3.25it/s]\u001b[A\n"," 52%|█████▏    | 350/679 [01:49<01:41,  3.23it/s]\u001b[A\n"," 52%|█████▏    | 351/679 [01:49<01:41,  3.24it/s]\u001b[A\n"," 52%|█████▏    | 352/679 [01:49<01:40,  3.27it/s]\u001b[A\n"," 52%|█████▏    | 353/679 [01:50<01:39,  3.27it/s]\u001b[A\n"," 52%|█████▏    | 354/679 [01:50<01:39,  3.27it/s]\u001b[A\n"," 52%|█████▏    | 355/679 [01:50<01:39,  3.27it/s]\u001b[A\n"," 52%|█████▏    | 356/679 [01:51<01:39,  3.25it/s]\u001b[A\n"," 53%|█████▎    | 357/679 [01:51<01:38,  3.25it/s]\u001b[A\n"," 53%|█████▎    | 358/679 [01:51<01:38,  3.25it/s]\u001b[A\n"," 53%|█████▎    | 359/679 [01:51<01:38,  3.25it/s]\u001b[A\n"," 53%|█████▎    | 360/679 [01:52<01:37,  3.28it/s]\u001b[A\n"," 53%|█████▎    | 361/679 [01:52<01:37,  3.25it/s]\u001b[A\n"," 53%|█████▎    | 362/679 [01:52<01:36,  3.27it/s]\u001b[A\n"," 53%|█████▎    | 363/679 [01:53<01:38,  3.21it/s]\u001b[A\n"," 54%|█████▎    | 364/679 [01:53<01:36,  3.25it/s]\u001b[A\n"," 54%|█████▍    | 365/679 [01:53<01:36,  3.25it/s]\u001b[A\n"," 54%|█████▍    | 366/679 [01:54<01:36,  3.25it/s]\u001b[A\n"," 54%|█████▍    | 367/679 [01:54<01:35,  3.26it/s]\u001b[A\n"," 54%|█████▍    | 368/679 [01:54<01:35,  3.25it/s]\u001b[A\n"," 54%|█████▍    | 369/679 [01:55<01:35,  3.26it/s]\u001b[A\n"," 54%|█████▍    | 370/679 [01:55<01:34,  3.26it/s]\u001b[A\n"," 55%|█████▍    | 371/679 [01:55<01:34,  3.24it/s]\u001b[A\n"," 55%|█████▍    | 372/679 [01:55<01:34,  3.23it/s]\u001b[A\n"," 55%|█████▍    | 373/679 [01:56<01:34,  3.24it/s]\u001b[A\n"," 55%|█████▌    | 374/679 [01:56<01:34,  3.24it/s]\u001b[A\n"," 55%|█████▌    | 375/679 [01:56<01:34,  3.23it/s]\u001b[A\n"," 55%|█████▌    | 376/679 [01:57<01:35,  3.17it/s]\u001b[A\n"," 56%|█████▌    | 377/679 [01:57<01:34,  3.18it/s]\u001b[A\n"," 56%|█████▌    | 378/679 [01:57<01:33,  3.22it/s]\u001b[A\n"," 56%|█████▌    | 379/679 [01:58<01:33,  3.21it/s]\u001b[A\n"," 56%|█████▌    | 380/679 [01:58<01:32,  3.24it/s]\u001b[A\n"," 56%|█████▌    | 381/679 [01:58<01:32,  3.22it/s]\u001b[A\n"," 56%|█████▋    | 382/679 [01:59<01:31,  3.24it/s]\u001b[A\n"," 56%|█████▋    | 383/679 [01:59<01:31,  3.25it/s]\u001b[A\n"," 57%|█████▋    | 384/679 [01:59<01:30,  3.27it/s]\u001b[A\n"," 57%|█████▋    | 385/679 [02:00<01:32,  3.19it/s]\u001b[A\n"," 57%|█████▋    | 386/679 [02:00<01:36,  3.04it/s]\u001b[A\n"," 57%|█████▋    | 387/679 [02:00<01:37,  3.01it/s]\u001b[A\n"," 57%|█████▋    | 388/679 [02:01<01:38,  2.96it/s]\u001b[A\n"," 57%|█████▋    | 389/679 [02:01<01:39,  2.92it/s]\u001b[A\n"," 57%|█████▋    | 390/679 [02:01<01:39,  2.91it/s]\u001b[A\n"," 58%|█████▊    | 391/679 [02:02<01:35,  3.01it/s]\u001b[A\n"," 58%|█████▊    | 392/679 [02:02<01:32,  3.10it/s]\u001b[A\n"," 58%|█████▊    | 393/679 [02:02<01:31,  3.13it/s]\u001b[A\n"," 58%|█████▊    | 394/679 [02:03<01:29,  3.17it/s]\u001b[A\n"," 58%|█████▊    | 395/679 [02:03<01:28,  3.20it/s]\u001b[A\n"," 58%|█████▊    | 396/679 [02:03<01:28,  3.19it/s]\u001b[A\n"," 58%|█████▊    | 397/679 [02:03<01:27,  3.22it/s]\u001b[A\n"," 59%|█████▊    | 398/679 [02:04<01:27,  3.22it/s]\u001b[A\n"," 59%|█████▉    | 399/679 [02:04<01:26,  3.22it/s]\u001b[A\n"," 59%|█████▉    | 400/679 [02:04<01:26,  3.24it/s]\u001b[A\n"," 59%|█████▉    | 401/679 [02:05<01:25,  3.23it/s]\u001b[A\n"," 59%|█████▉    | 402/679 [02:05<01:25,  3.24it/s]\u001b[A\n"," 59%|█████▉    | 403/679 [02:05<01:25,  3.24it/s]\u001b[A\n"," 59%|█████▉    | 404/679 [02:06<01:24,  3.27it/s]\u001b[A\n"," 60%|█████▉    | 405/679 [02:06<01:24,  3.23it/s]\u001b[A\n"," 60%|█████▉    | 406/679 [02:06<01:24,  3.25it/s]\u001b[A\n"," 60%|█████▉    | 407/679 [02:07<01:23,  3.24it/s]\u001b[A\n"," 60%|██████    | 408/679 [02:07<01:23,  3.24it/s]\u001b[A\n"," 60%|██████    | 409/679 [02:07<01:22,  3.26it/s]\u001b[A\n"," 60%|██████    | 410/679 [02:07<01:22,  3.26it/s]\u001b[A\n"," 61%|██████    | 411/679 [02:08<01:22,  3.25it/s]\u001b[A\n"," 61%|██████    | 412/679 [02:08<01:23,  3.21it/s]\u001b[A\n"," 61%|██████    | 413/679 [02:08<01:22,  3.23it/s]\u001b[A\n"," 61%|██████    | 414/679 [02:09<01:21,  3.25it/s]\u001b[A\n"," 61%|██████    | 415/679 [02:09<01:22,  3.22it/s]\u001b[A\n"," 61%|██████▏   | 416/679 [02:09<01:21,  3.21it/s]\u001b[A\n"," 61%|██████▏   | 417/679 [02:10<01:21,  3.21it/s]\u001b[A\n"," 62%|██████▏   | 418/679 [02:10<01:20,  3.23it/s]\u001b[A\n"," 62%|██████▏   | 419/679 [02:10<01:20,  3.22it/s]\u001b[A\n"," 62%|██████▏   | 420/679 [02:11<01:20,  3.22it/s]\u001b[A\n"," 62%|██████▏   | 421/679 [02:11<01:20,  3.22it/s]\u001b[A\n"," 62%|██████▏   | 422/679 [02:11<01:19,  3.25it/s]\u001b[A\n"," 62%|██████▏   | 423/679 [02:11<01:18,  3.25it/s]\u001b[A\n"," 62%|██████▏   | 424/679 [02:12<01:17,  3.27it/s]\u001b[A\n"," 63%|██████▎   | 425/679 [02:12<01:17,  3.28it/s]\u001b[A\n"," 63%|██████▎   | 426/679 [02:12<01:17,  3.28it/s]\u001b[A\n"," 63%|██████▎   | 427/679 [02:13<01:17,  3.26it/s]\u001b[A\n"," 63%|██████▎   | 428/679 [02:13<01:16,  3.26it/s]\u001b[A\n"," 63%|██████▎   | 429/679 [02:13<01:16,  3.28it/s]\u001b[A\n"," 63%|██████▎   | 430/679 [02:14<01:16,  3.27it/s]\u001b[A\n"," 63%|██████▎   | 431/679 [02:14<01:15,  3.27it/s]\u001b[A\n"," 64%|██████▎   | 432/679 [02:14<01:15,  3.26it/s]\u001b[A\n"," 64%|██████▍   | 433/679 [02:15<01:15,  3.27it/s]\u001b[A\n"," 64%|██████▍   | 434/679 [02:15<01:14,  3.28it/s]\u001b[A\n"," 64%|██████▍   | 435/679 [02:15<01:14,  3.26it/s]\u001b[A\n"," 64%|██████▍   | 436/679 [02:15<01:14,  3.27it/s]\u001b[A\n"," 64%|██████▍   | 437/679 [02:16<01:13,  3.28it/s]\u001b[A\n"," 65%|██████▍   | 438/679 [02:16<01:13,  3.29it/s]\u001b[A\n"," 65%|██████▍   | 439/679 [02:16<01:13,  3.29it/s]\u001b[A\n"," 65%|██████▍   | 440/679 [02:17<01:13,  3.24it/s]\u001b[A\n"," 65%|██████▍   | 441/679 [02:17<01:13,  3.24it/s]\u001b[A\n"," 65%|██████▌   | 442/679 [02:17<01:13,  3.23it/s]\u001b[A\n"," 65%|██████▌   | 443/679 [02:18<01:12,  3.26it/s]\u001b[A\n"," 65%|██████▌   | 444/679 [02:18<01:12,  3.25it/s]\u001b[A\n"," 66%|██████▌   | 445/679 [02:18<01:11,  3.26it/s]\u001b[A\n"," 66%|██████▌   | 446/679 [02:19<01:11,  3.25it/s]\u001b[A\n"," 66%|██████▌   | 447/679 [02:19<01:11,  3.25it/s]\u001b[A\n"," 66%|██████▌   | 448/679 [02:19<01:10,  3.27it/s]\u001b[A\n"," 66%|██████▌   | 449/679 [02:19<01:09,  3.29it/s]\u001b[A\n"," 66%|██████▋   | 450/679 [02:20<01:09,  3.28it/s]\u001b[A\n"," 66%|██████▋   | 451/679 [02:20<01:09,  3.26it/s]\u001b[A\n"," 67%|██████▋   | 452/679 [02:20<01:09,  3.25it/s]\u001b[A\n"," 67%|██████▋   | 453/679 [02:21<01:09,  3.26it/s]\u001b[A\n"," 67%|██████▋   | 454/679 [02:21<01:09,  3.24it/s]\u001b[A\n"," 67%|██████▋   | 455/679 [02:21<01:09,  3.24it/s]\u001b[A\n"," 67%|██████▋   | 456/679 [02:22<01:08,  3.27it/s]\u001b[A\n"," 67%|██████▋   | 457/679 [02:22<01:07,  3.28it/s]\u001b[A\n"," 67%|██████▋   | 458/679 [02:22<01:07,  3.28it/s]\u001b[A\n"," 68%|██████▊   | 459/679 [02:22<01:06,  3.29it/s]\u001b[A\n"," 68%|██████▊   | 460/679 [02:23<01:06,  3.30it/s]\u001b[A\n"," 68%|██████▊   | 461/679 [02:23<01:06,  3.28it/s]\u001b[A\n"," 68%|██████▊   | 462/679 [02:23<01:06,  3.28it/s]\u001b[A\n"," 68%|██████▊   | 463/679 [02:24<01:06,  3.27it/s]\u001b[A\n"," 68%|██████▊   | 464/679 [02:24<01:05,  3.26it/s]\u001b[A\n"," 68%|██████▊   | 465/679 [02:24<01:05,  3.27it/s]\u001b[A\n"," 69%|██████▊   | 466/679 [02:25<01:05,  3.26it/s]\u001b[A\n"," 69%|██████▉   | 467/679 [02:25<01:05,  3.26it/s]\u001b[A\n"," 69%|██████▉   | 468/679 [02:25<01:04,  3.25it/s]\u001b[A\n"," 69%|██████▉   | 469/679 [02:26<01:04,  3.26it/s]\u001b[A\n"," 69%|██████▉   | 470/679 [02:26<01:04,  3.26it/s]\u001b[A\n"," 69%|██████▉   | 471/679 [02:26<01:04,  3.21it/s]\u001b[A\n"," 70%|██████▉   | 472/679 [02:27<01:06,  3.12it/s]\u001b[A\n"," 70%|██████▉   | 473/679 [02:27<01:05,  3.17it/s]\u001b[A\n"," 70%|██████▉   | 474/679 [02:27<01:04,  3.20it/s]\u001b[A\n"," 70%|██████▉   | 475/679 [02:27<01:03,  3.23it/s]\u001b[A\n"," 70%|███████   | 476/679 [02:28<01:02,  3.23it/s]\u001b[A\n"," 70%|███████   | 477/679 [02:28<01:01,  3.26it/s]\u001b[A\n"," 70%|███████   | 478/679 [02:28<01:01,  3.26it/s]\u001b[A\n"," 71%|███████   | 479/679 [02:29<01:01,  3.28it/s]\u001b[A\n"," 71%|███████   | 480/679 [02:29<01:00,  3.27it/s]\u001b[A\n"," 71%|███████   | 481/679 [02:29<01:00,  3.26it/s]\u001b[A\n"," 71%|███████   | 482/679 [02:30<01:00,  3.27it/s]\u001b[A\n"," 71%|███████   | 483/679 [02:30<00:59,  3.28it/s]\u001b[A\n"," 71%|███████▏  | 484/679 [02:30<00:59,  3.28it/s]\u001b[A\n"," 71%|███████▏  | 485/679 [02:30<00:58,  3.29it/s]\u001b[A\n"," 72%|███████▏  | 486/679 [02:31<00:58,  3.30it/s]\u001b[A\n"," 72%|███████▏  | 487/679 [02:31<00:58,  3.30it/s]\u001b[A\n"," 72%|███████▏  | 488/679 [02:31<00:59,  3.19it/s]\u001b[A\n"," 72%|███████▏  | 489/679 [02:32<01:01,  3.09it/s]\u001b[A\n"," 72%|███████▏  | 490/679 [02:32<01:00,  3.11it/s]\u001b[A\n"," 72%|███████▏  | 491/679 [02:32<01:00,  3.10it/s]\u001b[A\n"," 72%|███████▏  | 492/679 [02:33<01:00,  3.11it/s]\u001b[A\n"," 73%|███████▎  | 493/679 [02:33<01:01,  3.02it/s]\u001b[A\n"," 73%|███████▎  | 494/679 [02:33<01:00,  3.08it/s]\u001b[A\n"," 73%|███████▎  | 495/679 [02:34<00:58,  3.13it/s]\u001b[A\n"," 73%|███████▎  | 496/679 [02:34<00:57,  3.16it/s]\u001b[A\n"," 73%|███████▎  | 497/679 [02:34<00:56,  3.20it/s]\u001b[A\n"," 73%|███████▎  | 498/679 [02:35<00:56,  3.22it/s]\u001b[A\n"," 73%|███████▎  | 499/679 [02:35<00:55,  3.23it/s]\u001b[A\n"," 74%|███████▎  | 500/679 [02:35<00:55,  3.23it/s]\u001b[A\n"," 74%|███████▍  | 501/679 [02:36<00:55,  3.21it/s]\u001b[A\n"," 74%|███████▍  | 502/679 [02:36<00:54,  3.23it/s]\u001b[A\n"," 74%|███████▍  | 503/679 [02:36<00:54,  3.21it/s]\u001b[A\n"," 74%|███████▍  | 504/679 [02:37<00:55,  3.17it/s]\u001b[A\n"," 74%|███████▍  | 505/679 [02:37<00:54,  3.19it/s]\u001b[A\n"," 75%|███████▍  | 506/679 [02:37<00:53,  3.22it/s]\u001b[A\n"," 75%|███████▍  | 507/679 [02:37<00:52,  3.25it/s]\u001b[A\n"," 75%|███████▍  | 508/679 [02:38<00:52,  3.26it/s]\u001b[A\n"," 75%|███████▍  | 509/679 [02:38<00:52,  3.26it/s]\u001b[A\n"," 75%|███████▌  | 510/679 [02:38<00:52,  3.24it/s]\u001b[A\n"," 75%|███████▌  | 511/679 [02:39<00:51,  3.25it/s]\u001b[A\n"," 75%|███████▌  | 512/679 [02:39<00:51,  3.27it/s]\u001b[A\n"," 76%|███████▌  | 513/679 [02:39<00:50,  3.29it/s]\u001b[A\n"," 76%|███████▌  | 514/679 [02:40<00:50,  3.29it/s]\u001b[A\n"," 76%|███████▌  | 515/679 [02:40<00:49,  3.29it/s]\u001b[A\n"," 76%|███████▌  | 516/679 [02:40<00:49,  3.26it/s]\u001b[A\n"," 76%|███████▌  | 517/679 [02:40<00:49,  3.25it/s]\u001b[A\n"," 76%|███████▋  | 518/679 [02:41<00:49,  3.25it/s]\u001b[A\n"," 76%|███████▋  | 519/679 [02:41<00:49,  3.26it/s]\u001b[A\n"," 77%|███████▋  | 520/679 [02:41<00:48,  3.27it/s]\u001b[A\n"," 77%|███████▋  | 521/679 [02:42<00:48,  3.27it/s]\u001b[A\n"," 77%|███████▋  | 522/679 [02:42<00:48,  3.26it/s]\u001b[A\n"," 77%|███████▋  | 523/679 [02:42<00:48,  3.24it/s]\u001b[A\n"," 77%|███████▋  | 524/679 [02:43<00:47,  3.25it/s]\u001b[A\n"," 77%|███████▋  | 525/679 [02:43<00:47,  3.26it/s]\u001b[A\n"," 77%|███████▋  | 526/679 [02:43<00:47,  3.25it/s]\u001b[A\n"," 78%|███████▊  | 527/679 [02:44<00:46,  3.24it/s]\u001b[A\n"," 78%|███████▊  | 528/679 [02:44<00:46,  3.25it/s]\u001b[A\n"," 78%|███████▊  | 529/679 [02:44<00:46,  3.24it/s]\u001b[A\n"," 78%|███████▊  | 530/679 [02:44<00:45,  3.25it/s]\u001b[A\n"," 78%|███████▊  | 531/679 [02:45<00:45,  3.24it/s]\u001b[A\n"," 78%|███████▊  | 532/679 [02:45<00:45,  3.25it/s]\u001b[A\n"," 78%|███████▊  | 533/679 [02:45<00:45,  3.23it/s]\u001b[A\n"," 79%|███████▊  | 534/679 [02:46<00:44,  3.26it/s]\u001b[A\n"," 79%|███████▉  | 535/679 [02:46<00:44,  3.26it/s]\u001b[A\n"," 79%|███████▉  | 536/679 [02:46<00:44,  3.24it/s]\u001b[A\n"," 79%|███████▉  | 537/679 [02:47<00:43,  3.27it/s]\u001b[A\n"," 79%|███████▉  | 538/679 [02:47<00:43,  3.26it/s]\u001b[A\n"," 79%|███████▉  | 539/679 [02:47<00:42,  3.27it/s]\u001b[A\n"," 80%|███████▉  | 540/679 [02:48<00:42,  3.27it/s]\u001b[A\n"," 80%|███████▉  | 541/679 [02:48<00:42,  3.27it/s]\u001b[A\n"," 80%|███████▉  | 542/679 [02:48<00:41,  3.29it/s]\u001b[A\n"," 80%|███████▉  | 543/679 [02:48<00:41,  3.27it/s]\u001b[A\n"," 80%|████████  | 544/679 [02:49<00:41,  3.27it/s]\u001b[A\n"," 80%|████████  | 545/679 [02:49<00:40,  3.29it/s]\u001b[A\n"," 80%|████████  | 546/679 [02:49<00:40,  3.29it/s]\u001b[A\n"," 81%|████████  | 547/679 [02:50<00:40,  3.28it/s]\u001b[A\n"," 81%|████████  | 548/679 [02:50<00:40,  3.26it/s]\u001b[A\n"," 81%|████████  | 549/679 [02:50<00:40,  3.24it/s]\u001b[A\n"," 81%|████████  | 550/679 [02:51<00:39,  3.24it/s]\u001b[A\n"," 81%|████████  | 551/679 [02:51<00:39,  3.24it/s]\u001b[A\n"," 81%|████████▏ | 552/679 [02:51<00:39,  3.26it/s]\u001b[A\n"," 81%|████████▏ | 553/679 [02:52<00:38,  3.25it/s]\u001b[A\n"," 82%|████████▏ | 554/679 [02:52<00:38,  3.27it/s]\u001b[A\n"," 82%|████████▏ | 555/679 [02:52<00:37,  3.29it/s]\u001b[A\n"," 82%|████████▏ | 556/679 [02:52<00:37,  3.28it/s]\u001b[A\n"," 82%|████████▏ | 557/679 [02:53<00:37,  3.29it/s]\u001b[A\n"," 82%|████████▏ | 558/679 [02:53<00:36,  3.28it/s]\u001b[A\n"," 82%|████████▏ | 559/679 [02:53<00:36,  3.29it/s]\u001b[A\n"," 82%|████████▏ | 560/679 [02:54<00:36,  3.30it/s]\u001b[A\n"," 83%|████████▎ | 561/679 [02:54<00:36,  3.26it/s]\u001b[A\n"," 83%|████████▎ | 562/679 [02:54<00:35,  3.26it/s]\u001b[A\n"," 83%|████████▎ | 563/679 [02:55<00:35,  3.27it/s]\u001b[A\n"," 83%|████████▎ | 564/679 [02:55<00:35,  3.26it/s]\u001b[A\n"," 83%|████████▎ | 565/679 [02:55<00:35,  3.21it/s]\u001b[A\n"," 83%|████████▎ | 566/679 [02:55<00:34,  3.25it/s]\u001b[A\n"," 84%|████████▎ | 567/679 [02:56<00:34,  3.24it/s]\u001b[A\n"," 84%|████████▎ | 568/679 [02:56<00:34,  3.23it/s]\u001b[A\n"," 84%|████████▍ | 569/679 [02:56<00:34,  3.20it/s]\u001b[A\n"," 84%|████████▍ | 570/679 [02:57<00:34,  3.15it/s]\u001b[A\n"," 84%|████████▍ | 571/679 [02:57<00:34,  3.16it/s]\u001b[A\n"," 84%|████████▍ | 572/679 [02:57<00:33,  3.17it/s]\u001b[A\n"," 84%|████████▍ | 573/679 [02:58<00:33,  3.21it/s]\u001b[A\n"," 85%|████████▍ | 574/679 [02:58<00:32,  3.22it/s]\u001b[A\n"," 85%|████████▍ | 575/679 [02:58<00:32,  3.23it/s]\u001b[A\n"," 85%|████████▍ | 576/679 [02:59<00:31,  3.25it/s]\u001b[A\n"," 85%|████████▍ | 577/679 [02:59<00:47,  2.14it/s]\u001b[A\n"," 85%|████████▌ | 578/679 [03:00<00:42,  2.39it/s]\u001b[A\n"," 85%|████████▌ | 579/679 [03:00<00:38,  2.60it/s]\u001b[A\n"," 85%|████████▌ | 580/679 [03:00<00:35,  2.77it/s]\u001b[A\n"," 86%|████████▌ | 581/679 [03:01<00:33,  2.91it/s]\u001b[A\n"," 86%|████████▌ | 582/679 [03:01<00:32,  2.99it/s]\u001b[A\n"," 86%|████████▌ | 583/679 [03:01<00:31,  3.05it/s]\u001b[A\n"," 86%|████████▌ | 584/679 [03:02<00:30,  3.10it/s]\u001b[A\n"," 86%|████████▌ | 585/679 [03:02<00:29,  3.17it/s]\u001b[A\n"," 86%|████████▋ | 586/679 [03:02<00:29,  3.19it/s]\u001b[A\n"," 86%|████████▋ | 587/679 [03:03<00:28,  3.20it/s]\u001b[A\n"," 87%|████████▋ | 588/679 [03:03<00:28,  3.21it/s]\u001b[A\n"," 87%|████████▋ | 589/679 [03:03<00:28,  3.15it/s]\u001b[A\n"," 87%|████████▋ | 590/679 [03:04<00:28,  3.07it/s]\u001b[A\n"," 87%|████████▋ | 591/679 [03:04<00:29,  2.94it/s]\u001b[A\n"," 87%|████████▋ | 592/679 [03:04<00:30,  2.86it/s]\u001b[A\n"," 87%|████████▋ | 593/679 [03:05<00:30,  2.84it/s]\u001b[A\n"," 87%|████████▋ | 594/679 [03:05<00:29,  2.88it/s]\u001b[A\n"," 88%|████████▊ | 595/679 [03:05<00:27,  3.00it/s]\u001b[A\n"," 88%|████████▊ | 596/679 [03:06<00:27,  3.06it/s]\u001b[A\n"," 88%|████████▊ | 597/679 [03:06<00:26,  3.13it/s]\u001b[A\n"," 88%|████████▊ | 598/679 [03:06<00:25,  3.13it/s]\u001b[A\n"," 88%|████████▊ | 599/679 [03:07<00:25,  3.08it/s]\u001b[A\n"," 88%|████████▊ | 600/679 [03:07<00:25,  3.13it/s]\u001b[A\n"," 89%|████████▊ | 601/679 [03:07<00:24,  3.17it/s]\u001b[A\n"," 89%|████████▊ | 602/679 [03:07<00:24,  3.21it/s]\u001b[A\n"," 89%|████████▉ | 603/679 [03:08<00:23,  3.25it/s]\u001b[A\n"," 89%|████████▉ | 604/679 [03:08<00:23,  3.24it/s]\u001b[A\n"," 89%|████████▉ | 605/679 [03:08<00:22,  3.26it/s]\u001b[A\n"," 89%|████████▉ | 606/679 [03:09<00:22,  3.27it/s]\u001b[A\n"," 89%|████████▉ | 607/679 [03:09<00:22,  3.27it/s]\u001b[A\n"," 90%|████████▉ | 608/679 [03:09<00:21,  3.29it/s]\u001b[A\n"," 90%|████████▉ | 609/679 [03:10<00:21,  3.27it/s]\u001b[A\n"," 90%|████████▉ | 610/679 [03:10<00:21,  3.28it/s]\u001b[A\n"," 90%|████████▉ | 611/679 [03:10<00:20,  3.28it/s]\u001b[A\n"," 90%|█████████ | 612/679 [03:10<00:20,  3.24it/s]\u001b[A\n"," 90%|█████████ | 613/679 [03:11<00:20,  3.23it/s]\u001b[A\n"," 90%|█████████ | 614/679 [03:11<00:20,  3.23it/s]\u001b[A\n"," 91%|█████████ | 615/679 [03:11<00:19,  3.23it/s]\u001b[A\n"," 91%|█████████ | 616/679 [03:12<00:19,  3.27it/s]\u001b[A\n"," 91%|█████████ | 617/679 [03:12<00:19,  3.26it/s]\u001b[A\n"," 91%|█████████ | 618/679 [03:12<00:18,  3.26it/s]\u001b[A\n"," 91%|█████████ | 619/679 [03:13<00:18,  3.28it/s]\u001b[A\n"," 91%|█████████▏| 620/679 [03:13<00:18,  3.28it/s]\u001b[A\n"," 91%|█████████▏| 621/679 [03:13<00:17,  3.29it/s]\u001b[A\n"," 92%|█████████▏| 622/679 [03:14<00:17,  3.28it/s]\u001b[A\n"," 92%|█████████▏| 623/679 [03:14<00:17,  3.28it/s]\u001b[A\n"," 92%|█████████▏| 624/679 [03:14<00:16,  3.30it/s]\u001b[A\n"," 92%|█████████▏| 625/679 [03:14<00:16,  3.30it/s]\u001b[A\n"," 92%|█████████▏| 626/679 [03:15<00:16,  3.30it/s]\u001b[A\n"," 92%|█████████▏| 627/679 [03:15<00:15,  3.30it/s]\u001b[A\n"," 92%|█████████▏| 628/679 [03:15<00:15,  3.29it/s]\u001b[A\n"," 93%|█████████▎| 629/679 [03:16<00:15,  3.29it/s]\u001b[A\n"," 93%|█████████▎| 630/679 [03:16<00:15,  3.27it/s]\u001b[A\n"," 93%|█████████▎| 631/679 [03:16<00:14,  3.23it/s]\u001b[A\n"," 93%|█████████▎| 632/679 [03:17<00:14,  3.25it/s]\u001b[A\n"," 93%|█████████▎| 633/679 [03:17<00:14,  3.26it/s]\u001b[A\n"," 93%|█████████▎| 634/679 [03:17<00:13,  3.25it/s]\u001b[A\n"," 94%|█████████▎| 635/679 [03:18<00:13,  3.25it/s]\u001b[A\n"," 94%|█████████▎| 636/679 [03:18<00:13,  3.25it/s]\u001b[A\n"," 94%|█████████▍| 637/679 [03:18<00:12,  3.24it/s]\u001b[A\n"," 94%|█████████▍| 638/679 [03:18<00:12,  3.25it/s]\u001b[A\n"," 94%|█████████▍| 639/679 [03:19<00:12,  3.26it/s]\u001b[A\n"," 94%|█████████▍| 640/679 [03:19<00:12,  3.25it/s]\u001b[A\n"," 94%|█████████▍| 641/679 [03:19<00:11,  3.25it/s]\u001b[A\n"," 95%|█████████▍| 642/679 [03:20<00:11,  3.27it/s]\u001b[A\n"," 95%|█████████▍| 643/679 [03:20<00:11,  3.25it/s]\u001b[A\n"," 95%|█████████▍| 644/679 [03:20<00:10,  3.24it/s]\u001b[A\n"," 95%|█████████▍| 645/679 [03:21<00:10,  3.25it/s]\u001b[A\n"," 95%|█████████▌| 646/679 [03:21<00:10,  3.23it/s]\u001b[A\n"," 95%|█████████▌| 647/679 [03:21<00:09,  3.24it/s]\u001b[A\n"," 95%|█████████▌| 648/679 [03:22<00:09,  3.25it/s]\u001b[A\n"," 96%|█████████▌| 649/679 [03:22<00:09,  3.26it/s]\u001b[A\n"," 96%|█████████▌| 650/679 [03:22<00:08,  3.26it/s]\u001b[A\n"," 96%|█████████▌| 651/679 [03:22<00:08,  3.26it/s]\u001b[A\n"," 96%|█████████▌| 652/679 [03:23<00:08,  3.25it/s]\u001b[A\n"," 96%|█████████▌| 653/679 [03:23<00:07,  3.25it/s]\u001b[A\n"," 96%|█████████▋| 654/679 [03:23<00:07,  3.25it/s]\u001b[A\n"," 96%|█████████▋| 655/679 [03:24<00:07,  3.27it/s]\u001b[A\n"," 97%|█████████▋| 656/679 [03:24<00:06,  3.29it/s]\u001b[A\n"," 97%|█████████▋| 657/679 [03:24<00:06,  3.27it/s]\u001b[A\n"," 97%|█████████▋| 658/679 [03:25<00:06,  3.26it/s]\u001b[A\n"," 97%|█████████▋| 659/679 [03:25<00:06,  3.27it/s]\u001b[A\n"," 97%|█████████▋| 660/679 [03:25<00:05,  3.27it/s]\u001b[A\n"," 97%|█████████▋| 661/679 [03:26<00:05,  3.27it/s]\u001b[A\n"," 97%|█████████▋| 662/679 [03:26<00:05,  3.26it/s]\u001b[A\n"," 98%|█████████▊| 663/679 [03:26<00:04,  3.28it/s]\u001b[A\n"," 98%|█████████▊| 664/679 [03:26<00:04,  3.08it/s]\u001b[A\n"," 98%|█████████▊| 665/679 [03:27<00:04,  3.11it/s]\u001b[A\n"," 98%|█████████▊| 666/679 [03:27<00:04,  3.16it/s]\u001b[A\n"," 98%|█████████▊| 667/679 [03:27<00:03,  3.20it/s]\u001b[A\n"," 98%|█████████▊| 668/679 [03:28<00:03,  3.22it/s]\u001b[A\n"," 99%|█████████▊| 669/679 [03:28<00:03,  3.20it/s]\u001b[A\n"," 99%|█████████▊| 670/679 [03:28<00:02,  3.21it/s]\u001b[A\n"," 99%|█████████▉| 671/679 [03:29<00:02,  3.22it/s]\u001b[A\n"," 99%|█████████▉| 672/679 [03:29<00:02,  3.23it/s]\u001b[A\n"," 99%|█████████▉| 673/679 [03:29<00:01,  3.24it/s]\u001b[A\n"," 99%|█████████▉| 674/679 [03:30<00:01,  3.23it/s]\u001b[A\n"," 99%|█████████▉| 675/679 [03:30<00:01,  3.26it/s]\u001b[A\n","100%|█████████▉| 676/679 [03:30<00:00,  3.32it/s]\u001b[A\n","100%|█████████▉| 677/679 [03:30<00:00,  3.35it/s]\u001b[A\n","100%|█████████▉| 678/679 [03:31<00:00,  3.36it/s]\u001b[A\n","100%|██████████| 679/679 [03:31<00:00,  3.21it/s]\u001b[A\n","\n","  0%|          | 0/85 [00:00<?, ?it/s]\u001b[A\n","  1%|          | 1/85 [00:00<00:24,  3.38it/s]\u001b[A\n","  2%|▏         | 2/85 [00:00<00:18,  4.45it/s]\u001b[A\n","  4%|▎         | 3/85 [00:00<00:16,  4.91it/s]\u001b[A\n","  5%|▍         | 4/85 [00:00<00:15,  5.15it/s]\u001b[A\n","  6%|▌         | 5/85 [00:01<00:15,  5.31it/s]\u001b[A\n","  7%|▋         | 6/85 [00:01<00:14,  5.39it/s]\u001b[A\n","  8%|▊         | 7/85 [00:01<00:14,  5.48it/s]\u001b[A\n","  9%|▉         | 8/85 [00:01<00:13,  5.55it/s]\u001b[A\n"," 11%|█         | 9/85 [00:01<00:13,  5.60it/s]\u001b[A\n"," 12%|█▏        | 10/85 [00:01<00:13,  5.56it/s]\u001b[A\n"," 13%|█▎        | 11/85 [00:02<00:13,  5.63it/s]\u001b[A\n"," 14%|█▍        | 12/85 [00:02<00:12,  5.69it/s]\u001b[A\n"," 15%|█▌        | 13/85 [00:02<00:12,  5.73it/s]\u001b[A\n"," 16%|█▋        | 14/85 [00:02<00:12,  5.73it/s]\u001b[A\n"," 18%|█▊        | 15/85 [00:02<00:12,  5.68it/s]\u001b[A\n"," 19%|█▉        | 16/85 [00:02<00:12,  5.61it/s]\u001b[A\n"," 20%|██        | 17/85 [00:03<00:11,  5.67it/s]\u001b[A\n"," 21%|██        | 18/85 [00:03<00:11,  5.71it/s]\u001b[A\n"," 22%|██▏       | 19/85 [00:03<00:11,  5.67it/s]\u001b[A\n"," 24%|██▎       | 20/85 [00:03<00:11,  5.69it/s]\u001b[A\n"," 25%|██▍       | 21/85 [00:03<00:11,  5.67it/s]\u001b[A\n"," 26%|██▌       | 22/85 [00:04<00:11,  5.43it/s]\u001b[A\n"," 27%|██▋       | 23/85 [00:04<00:11,  5.33it/s]\u001b[A\n"," 28%|██▊       | 24/85 [00:04<00:12,  5.00it/s]\u001b[A\n"," 29%|██▉       | 25/85 [00:04<00:12,  4.87it/s]\u001b[A\n"," 31%|███       | 26/85 [00:04<00:12,  4.78it/s]\u001b[A\n"," 32%|███▏      | 27/85 [00:05<00:12,  4.50it/s]\u001b[A\n"," 33%|███▎      | 28/85 [00:05<00:13,  4.35it/s]\u001b[A\n"," 34%|███▍      | 29/85 [00:05<00:13,  4.08it/s]\u001b[A\n"," 35%|███▌      | 30/85 [00:05<00:12,  4.40it/s]\u001b[A\n"," 36%|███▋      | 31/85 [00:06<00:11,  4.73it/s]\u001b[A\n"," 38%|███▊      | 32/85 [00:06<00:10,  4.95it/s]\u001b[A\n"," 39%|███▉      | 33/85 [00:06<00:10,  5.13it/s]\u001b[A\n"," 40%|████      | 34/85 [00:06<00:09,  5.32it/s]\u001b[A\n"," 41%|████      | 35/85 [00:06<00:09,  5.40it/s]\u001b[A\n"," 42%|████▏     | 36/85 [00:06<00:08,  5.52it/s]\u001b[A\n"," 44%|████▎     | 37/85 [00:07<00:08,  5.65it/s]\u001b[A\n"," 45%|████▍     | 38/85 [00:07<00:08,  5.72it/s]\u001b[A\n"," 46%|████▌     | 39/85 [00:07<00:08,  5.72it/s]\u001b[A\n"," 47%|████▋     | 40/85 [00:07<00:07,  5.71it/s]\u001b[A\n"," 48%|████▊     | 41/85 [00:07<00:07,  5.68it/s]\u001b[A\n"," 49%|████▉     | 42/85 [00:07<00:07,  5.72it/s]\u001b[A\n"," 51%|█████     | 43/85 [00:08<00:07,  5.74it/s]\u001b[A\n"," 52%|█████▏    | 44/85 [00:08<00:07,  5.75it/s]\u001b[A\n"," 53%|█████▎    | 45/85 [00:08<00:06,  5.81it/s]\u001b[A\n"," 54%|█████▍    | 46/85 [00:08<00:06,  5.82it/s]\u001b[A\n"," 55%|█████▌    | 47/85 [00:08<00:06,  5.81it/s]\u001b[A\n"," 56%|█████▋    | 48/85 [00:08<00:06,  5.81it/s]\u001b[A\n"," 58%|█████▊    | 49/85 [00:09<00:06,  5.80it/s]\u001b[A\n"," 59%|█████▉    | 50/85 [00:09<00:05,  5.87it/s]\u001b[A\n"," 60%|██████    | 51/85 [00:09<00:05,  5.80it/s]\u001b[A\n"," 61%|██████    | 52/85 [00:09<00:05,  5.82it/s]\u001b[A\n"," 62%|██████▏   | 53/85 [00:09<00:05,  5.74it/s]\u001b[A\n"," 64%|██████▎   | 54/85 [00:10<00:05,  5.76it/s]\u001b[A\n"," 65%|██████▍   | 55/85 [00:10<00:05,  5.69it/s]\u001b[A\n"," 66%|██████▌   | 56/85 [00:10<00:05,  5.70it/s]\u001b[A\n"," 67%|██████▋   | 57/85 [00:10<00:04,  5.66it/s]\u001b[A\n"," 68%|██████▊   | 58/85 [00:10<00:04,  5.64it/s]\u001b[A\n"," 69%|██████▉   | 59/85 [00:10<00:04,  5.69it/s]\u001b[A\n"," 71%|███████   | 60/85 [00:11<00:04,  5.75it/s]\u001b[A\n"," 72%|███████▏  | 61/85 [00:11<00:04,  5.73it/s]\u001b[A\n"," 73%|███████▎  | 62/85 [00:11<00:04,  5.73it/s]\u001b[A\n"," 74%|███████▍  | 63/85 [00:11<00:03,  5.76it/s]\u001b[A\n"," 75%|███████▌  | 64/85 [00:11<00:03,  5.83it/s]\u001b[A\n"," 76%|███████▋  | 65/85 [00:11<00:03,  5.83it/s]\u001b[A\n"," 78%|███████▊  | 66/85 [00:12<00:03,  5.74it/s]\u001b[A\n"," 79%|███████▉  | 67/85 [00:12<00:03,  5.64it/s]\u001b[A\n"," 80%|████████  | 68/85 [00:12<00:03,  5.52it/s]\u001b[A\n"," 81%|████████  | 69/85 [00:12<00:02,  5.56it/s]\u001b[A\n"," 82%|████████▏ | 70/85 [00:12<00:02,  5.56it/s]\u001b[A\n"," 84%|████████▎ | 71/85 [00:13<00:02,  5.66it/s]\u001b[A\n"," 85%|████████▍ | 72/85 [00:13<00:02,  5.69it/s]\u001b[A\n"," 86%|████████▌ | 73/85 [00:13<00:02,  5.72it/s]\u001b[A\n"," 87%|████████▋ | 74/85 [00:13<00:01,  5.62it/s]\u001b[A\n"," 88%|████████▊ | 75/85 [00:13<00:01,  5.61it/s]\u001b[A\n"," 89%|████████▉ | 76/85 [00:13<00:01,  5.64it/s]\u001b[A\n"," 91%|█████████ | 77/85 [00:14<00:01,  5.60it/s]\u001b[A\n"," 92%|█████████▏| 78/85 [00:14<00:01,  5.62it/s]\u001b[A\n"," 93%|█████████▎| 79/85 [00:14<00:01,  5.65it/s]\u001b[A\n"," 94%|█████████▍| 80/85 [00:14<00:00,  5.65it/s]\u001b[A\n"," 95%|█████████▌| 81/85 [00:14<00:00,  5.66it/s]\u001b[A\n"," 96%|█████████▋| 82/85 [00:14<00:00,  5.66it/s]\u001b[A\n"," 98%|█████████▊| 83/85 [00:15<00:00,  5.72it/s]\u001b[A\n"," 99%|█████████▉| 84/85 [00:15<00:00,  5.91it/s]\u001b[A\n","100%|██████████| 85/85 [00:15<00:00,  5.47it/s]\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["Model saved as current val_loss is:  0.10415135797332314\n"]}],"source":["import mlflow.pytorch\n","\n","experiment_name = \"Distill Bert\"\n","experiment = mlflow.get_experiment_by_name(experiment_name)\n","if experiment is None:\n","    experiment_id = mlflow.create_experiment(experiment_name)\n","else:\n","    experiment_id = experiment.experiment_id\n","    \n","    \n","mlflow.set_tracking_uri(\"http://13.233.157.244:5001/\")\n","# mlflow.pytorch.autolog()\n","\n","# with mlflow.start_run(experiment_id=experiment_id, run_name=\"Run 13\"):\n","# #     mlflow.pytorch.autolog()\n","#      # Enable automatic logging for PyTorch\n","# #     trained_model=trainer()\n","#     \n","trainer()"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-08-28T11:41:39.529403Z","iopub.status.busy":"2023-08-28T11:41:39.528482Z","iopub.status.idle":"2023-08-28T11:41:39.535119Z","shell.execute_reply":"2023-08-28T11:41:39.533799Z","shell.execute_reply.started":"2023-08-28T11:41:39.529359Z"},"trusted":true},"outputs":[],"source":["mlflow.end_run()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["/kaggle/working/best_model.pt"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
